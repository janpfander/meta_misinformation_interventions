{
  "hash": "694566ed40b46e2211ab93d2ae12aa95",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: |\n  Data simulation for preregistration\ntitle-block-banner: true\nexecute:\n  message: false\n  warning: false\n  \nbibliography: ../references.bib\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# load plot theme\nsource(\"../R/plot_theme.R\") \n\n# load other functions\nsource(\"../R/custom_functions.R\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set a seed\nset.seed(1234)\n```\n:::\n\n\n\n\n\n# Introduction\n\nWe will generate participant-level data for a set different papers with different numbers of experiments.\n\nThis simulation involves three steps:\n\n1. simulate data for a single experiment\n2. simulate several experiments\n3. simulate several papers \n\nTo give an overview of the data generating task: \n\nWe model our dependent variable `accuracy` based on the variables `veracity` (false vs. true), `condition` (control vs. intervention), and their interaction. We have random effects for `subject_id`, `experiment_id` and `paper_id`. \n\n# Building a simulation function\n\n## Data generating process\n\n### Variables\n\n- `paper_id` (identifier of the published paper)\n- `experiment_id` (identifier of experiments within a paper)\n- `subject_id` (identifier of subjects within an experiment)\n- `veracity`  (true vs. fake news)\n- `accuracy` (numeric accuracy rating, ranging from 0 to 1)^[for binary variables, this is the probability of choosing accurate as an answer.]\n- `condition` (control vs. intervention)\n- `n` (number of participants per sample)\n\n### Design\n\nThe important parts of the design are:\n\n* Random factors : \n    * `subject_id` \n    * `experiment_id`\n    * `paper_id`\n* Fixed factor 1: `veracity` (levels = false, true)\n    * within subject_id \n    * within experiment_id\n    * within paper_id\n    \n* Fixed factor 2: `condition` (levels: control, intervention)\n    * between subject_id\n    * within experiment_id\n    * within paper_id\n    \n* Fixed factor 3: `condition\\*veracity` \n    * between subject_id\n    * within experiment_id\n    * within paper_id\n\nWe assume that,\n\n* `veracity` varies _within_ participants, i.e. all participants see both `fake` and `true` news \n* `condition` varies _between_ participants, i.e. a participant is either in the control group or a treatment group\n* an experiment involves only one control group, but a varying number of treatment groups (up to 3)\n* we assume _random effects_ only for participants (`subject_id`), experiments (`experiment_id`) and papers (`paper_id`). We do *not* assume, random effects for different intervention types, nor for different news headlines\n* the sample size per experimental condition is 100\n* each participant rates 12 news items in total, with equal numbers of `fake` and `true` items\n    \n### Model\n\nWe use a generalized linear mixed model (GLMM) to generate accuracy responses. In this model, our parameters are z-values. For the interpretation of our model parameters below in terms of Signal Detection Theory (SDT) outcomes (sensitivity \"d prime\" and the response bias \"c\"), it is crucial that we use deviation coding for our veracity variable (fake = -0.5, true = 0.5), and for condition (-0.5 = control, 0.5 = intervention).\n\n\\begin{align*}\n\\eta_i &= (\\beta_0 + b_{0_\\text{Subject}} + b_{0_\\text{Experiment}} + b_{0_\\text{Paper}}) \\\\\n&\\quad+ (\\beta_v + b_{v_\\text{Subject}} + b_{v_\\text{Experiment}} + b_{v_\\text{Paper}}) \\text{Veracity} \\\\\n&\\quad+ (\\beta_c + b_{c_\\text{Experiment}} + b_{c_\\text{Paper}}) \\text{Condition} \\\\\n&\\quad+ (\\beta_{cv} + b_{cv_\\text{Experiment}} + b_{cv_\\text{Paper}}) \\text{Condition*Veracity} + \\epsilon\n\\end{align*}\n\nwith^[Note that the distributions here are assumed to be independent. Below, we specify that they are from multivariate distributions.]:\n\n-   \\(b_{0_{\\text{Subject}}} \\sim N(0, \\tau_{\\text{subj}_0})\\)\n-   \\(b_{v_{\\text{Subject}}} \\sim N(0, \\tau_{\\text{subj}_v})\\)\n-   \\(b_{0_{\\text{Experiment}}} \\sim N(0, \\tau_{\\text{exp}_0})\\) \n-   \\(b_{v_{\\text{Experiment}}} \\sim N(0, \\tau_{\\text{exp}_v})\\)\n-   \\(b_{c_{\\text{Experiment}}} \\sim N(0, \\tau_{\\text{exp}_c})\\)\n-   \\(b_{cv_{\\text{Experiment}}} \\sim N(0, \\tau_{\\text{exp}_cv})\\)\n-   \\(b_{0_{\\text{Paper}}} \\sim N(0, \\tau_{\\text{paper}_0})\\)\n-   \\(b_{v_{\\text{Paper}}} \\sim N(0, \\tau_{\\text{paper}_v})\\)\n-   \\(b_{c_{\\text{Paper}}} \\sim N(0, \\tau_{\\text{paper}_c})\\)\n-   \\(b_{cv_{\\text{Paper}}} \\sim N(0, \\tau_{\\text{paper}_cv})\\)\n-   \\(\\epsilon \\sim N(0, \\sigma)\\)\n\nwhere:\n\n- \\eta_i is a z-score that can be transformed to a probability for an accuracy answer, using the probit function\n\n-   \\(\\beta_0\\) represents - the average response bias (c), pooled across conditions\n\n-   \\(b_{0_{\\text{Subject}}}\\), \\(b_{0_{\\text{Experiment}}}\\), and \\(b_{0_{\\text{Paper}}}\\) are the subject-, experiment-, and paper-specific deviations from the average intercept.\n\n-   \\(\\beta_v\\) represents the average sensitivity (d') across the conditions\n\n-   \\(b_{v_{\\text{Subject}}}\\), \\(b_{v_{\\text{Experiment}}}\\), and \\(b_{v_{\\text{Paper}}}\\) are the subject-, experiment-, and paper-specific deviations from the average sensitivity (d')\n\n-   \\(\\beta_c\\) reflects -$\\Delta c$, i.e. the change in -response bias between control and treatment\n\n-   \\(b_{c_{\\text{Experiment}}}\\) and \\(b_{c_{\\text{Paper}}}\\) are the experiment-, and paper-specific deviations from -$\\Delta c$\n\n-   \\(\\beta_{cv}\\) reflects $\\Delta d'$, i.e. the change in sensitivity between treatment and control\n\n-   \\(b_{cv_{\\text{Experiment}}}\\) and \\(b_{cv_{\\text{Paper}}}\\) are the experiment-, and paper-specific deviations from the average $\\Delta d'$\n\n-   $\\epsilon$ is the error term that represents noise not accounted for by the random effects\n\n-   $\\sigma$ is the standard deviation of the normal distribution that of the error term.\n\n-   $\\tau$'s are the respective standard deviations of the normal distributions of the random effects. We assume that the deviations of subjects are normally distributed around the average effects (hence a mean of `0`). Some subjects will have a positive deviation (i.e. larger values than the average); some will have a negative offset (i.e. smaller values than the average).\n\nThe modelling of random effects as described above was simplified. It suggested that all random effects are described by independent normal distributions. But in fact, should expect that all random effects, of for example a single subject, are correlated. For example, subjects with a relatively *small intercept* (i.e. assigning very low accuracy when to false news) might assign all the more accuracy to true news (i.e shows a *larger effect for veracity*). In this case, the random effect distributions of the intercept and the effect of veracity for subjects are *negatively* correlated.\n\nFor each random effect factor (subjects, experiments, papers) we therefore model multivariate normal distributions.\n\n\\[\n\\langle b_{0_{\\text{Subject}}}, b_{v_{\\text{Subject}}} \\rangle \\sim N(\\langle 0, 0 \\rangle, \\Sigma)\n\\]\n\nwith variance-covariance matrix\n\n\\[\n\\Sigma = \\begin{bmatrix} \\tau_{0_{\\text{subj}}}^2 & \\rho_{0v_{\\text{subj}}} \\tau_{0_{\\text{subj}}} \\tau_{v_{\\text{subj}}} \\\\ \\rho_{0v_{\\text{subj}}} \\tau_{0_{\\text{subj}}} \\tau_{v_{\\text{subj}}} & \\tau_{v_{\\text{subj}}}^2 \\end{bmatrix}\n\\]\n\n\\[\n\\langle b_{0_{\\text{Experiment}}}, b_{v_{\\text{Experiment}}}, b_{c_{\\text{Experiment}}}, b_{cv_{\\text{Experiment}}} \\rangle \\sim N(\\langle 0, 0, 0 \\rangle, \\Sigma)\n\\]\n\nwith variance-covariance matrix\n\n\\[\n\\Sigma = \\begin{bmatrix} \n\\tau_{0_{\\text{exp}}}^2 & \\rho_{0v_{\\text{exp}}} \\tau_{0_{\\text{exp}}} \\tau_{v_{\\text{exp}}} & \\rho_{0c_{\\text{exp}}} \\tau_{0_{\\text{exp}}} \\tau_{c_{\\text{exp}}} & \\rho_{0cv_{\\text{exp}}} \\tau_{0_{\\text{exp}}} \\tau_{cv_{\\text{exp}}} \\\\\n\\rho_{0v_{\\text{exp}}} \\tau_{0_{\\text{exp}}} \\tau_{v_{\\text{exp}}} & \\tau_{v_{\\text{exp}}}^2 & \\rho_{vc_{\\text{exp}}} \\tau_{v_{\\text{exp}}} \\tau_{c_{\\text{exp}}} & \\rho_{vcv_{\\text{exp}}} \\tau_{v_{\\text{exp}}} \\tau_{cv_{\\text{exp}}} \\\\\n\\rho_{0c_{\\text{exp}}} \\tau_{0_{\\text{exp}}} \\tau_{c_{\\text{exp}}} & \\rho_{vc_{\\text{exp}}} \\tau_{v_{\\text{exp}}} \\tau_{c_{\\text{exp}}} & \\tau_{c_{\\text{exp}}}^2  & \\rho_{ccv_{\\text{exp}}} \\tau_{c_{\\text{exp}}} \\tau_{cv_{\\text{exp}}} \\\\\n\\rho_{0cv_{\\text{exp}}} \\tau_{0_{\\text{exp}}} \\tau_{cv_{\\text{exp}}} & \\rho_{vcv_{\\text{exp}}} \\tau_{v_{\\text{exp}}} \\tau_{cv_{\\text{exp}}} & \\rho_{ccv_{\\text{exp}}} \\tau_{c_{\\text{exp}}} \\tau_{cv_{\\text{exp}}} & \\tau_{cv_{\\text{exp}}}^2 \n\\end{bmatrix}\n\\]\n\n\\[\n\\langle b_{0_{\\text{Paper}}}, b_{v_{\\text{Paper}}}, b_{c_{\\text{Paper}}}, b_{cv_{\\text{Paper}}} \\rangle \\sim N(\\langle 0, 0, 0 \\rangle, \\Sigma)\n\\]\n\nwith variance-covariance matrix\n\n\\[\n\\Sigma = \\begin{bmatrix} \n\\tau_{0_{\\text{paper}}}^2 & \\rho_{0v_{\\text{paper}}} \\tau_{0_{\\text{paper}}} \\tau_{v_{\\text{paper}}} & \\rho_{0c_{\\text{paper}}} \\tau_{0_{\\text{paper}}} \\tau_{c_{\\text{paper}}} & \\rho_{0cv_{\\text{paper}}} \\tau_{0_{\\text{paper}}} \\tau_{cv_{\\text{paper}}} \\\\\n\\rho_{0v_{\\text{paper}}} \\tau_{0_{\\text{paper}}} \\tau_{v_{\\text{paper}}} & \\tau_{v_{\\text{paper}}}^2 & \\rho_{vc_{\\text{paper}}} \\tau_{v_{\\text{paper}}} \\tau_{c_{\\text{paper}}} & \\rho_{vcv_{\\text{paper}}} \\tau_{v_{\\text{paper}}} \\tau_{cv_{\\text{paper}}} \\\\\n\\rho_{0c_{\\text{paper}}} \\tau_{0_{\\text{paper}}} \\tau_{c_{\\text{paper}}} & \\rho_{vc_{\\text{paper}}} \\tau_{v_{\\text{paper}}} \\tau_{c_{\\text{paper}}} & \\tau_{c_{\\text{paper}}}^2  & \\rho_{ccv_{\\text{paper}}} \\tau_{c_{\\text{paper}}} \\tau_{cv_{\\text{paper}}} \\\\\n\\rho_{0cv_{\\text{paper}}} \\tau_{0_{\\text{paper}}} \\tau_{cv_{\\text{paper}}} & \\rho_{vcv_{\\text{paper}}} \\tau_{v_{\\text{paper}}} \\tau_{cv_{\\text{paper}}} & \\rho_{ccv_{\\text{paper}}} \\tau_{c_{\\text{paper}}} \\tau_{cv_{\\text{paper}}} & \\tau_{cv_{\\text{paper}}}^2 \n\\end{bmatrix}\n\\]\n\nwhere\n\n-   $\\tau$'s are the standard deviations of the random effects distributions\n\n-   $\\rho$'s are the correlation coefficients.\n\nWe then transform the z-values $\\eta_i$ to probabilities using the probit function.\n\n$$p_i = \\Phi(\\eta_i)$$\nwhere $\\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution (or probit function). It maps the z-scores ($\\eta_i$) to probabilities.\n\n$$\n\\Phi(\\eta_i) = \\int_{-\\infty}^{\\eta_i} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{z^2}{2}} \\, dz\n$$\n\nThe integral calculates the area under the standard normal curve from negative infinity up to the value $\\eta_i$ and thus translates the z-value into a cumulative probability, which represents the likelihood of observing a value less than or equal to $\\eta_i$.\n\nBased on these probabilities, we simulate binary response (accurate = 1 or not accurate = 0), by using a Bernoulli (i.e. a binomial with one trial) function.  \n\n$$y_i \\sim Bernoulli(p_i)$$\n\n### Parameters\n\nWe use the following prefixes to designate model parameters and sampled values: \n\n- `beta_*`: fixed effect parameters\n- `subj_*`: random effect parameters associated with subjects\n- `exp_*`: random effect parameters associated with experiment\n- `paper_*`: random effect parameters associated with paper\n- `SU_*`: sampled values for subject random effects\n- `EXP_*`: sampled values for experiment random effects\n- `PAP_*`: sampled values for paper random effects\n- `B_*`: sums of added beta's\n- `e_*`: residual sd\n\nWe use the following suffices to refer to certain variables:\n\n- `*_0`: intercept\n- `*_v`: veracity\n- `*_c`: condition\n- `*_cv`: condition\\*veracity (interaction)\n\nOther terms:\n\n- `*_rho`: correlations for that group's random effects\n- `n_*`: sample size\n- `sigma`: residual (error) sd\n\nBelow, we set our parameters. The values are probably off, but the main point is to see how well our analysis does in uncovering them. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# parameters\n\n# fixed effects\nbeta_0   = -0 # intercept (- average response bias )\nbeta_v   = 1 # average sensitivity (d prime) \nbeta_c   = -0.5 # - delta response bias (i.e. - delta c)\nbeta_cv   = 0.5 # delta sensitivity (i.e. delta d prime)\n# random effects\n# subjects\nsubj_0   = 0.1 # by-subject intercept sd\nsubj_v   = 0.1 # by-subject sensitivity (d prime) sd\nsubj_rho_0v = 0 # correlation between intercept (- average response bias) and sensitivity (d prime)\n# experiments\nexp_0   = 0.1 # by-experiment intercept sd\nexp_v   = 0.1 # by-experiment sensitivity (d prime) sd\nexp_c   = 0.1 # by-experiment - delta response bias (i.e. - delta c) sd\nexp_cv   = 0.1 # by-experiment delta sensitivity (i.e. delta d prime) sd\nexp_rho_0v = 0 # correlation between intercept (- average response bias) and sensitivity (d prime)\nexp_rho_0c = 0 # correlation between intercept and - delta response bias (i.e. - delta c)\nexp_rho_0cv = 0 # correlation between intercept (- average response bias) and delta sensitivity (i.e. delta d prime)\nexp_rho_vc = 0 # correlation between sensitivity (d prime) and - delta response bias (i.e. - delta c)\nexp_rho_vcv = 0 # correlation between sensitivity (d prime) and delta sensitivity (i.e. delta d prime)\nexp_rho_ccv = 0 # correlation between - delta response bias (i.e. - delta c) and delta sensitivity (i.e. delta d prime)\n# papers\npaper_0   = 0.1 # analogous to experiment random effects\npaper_v   = 0.1 \npaper_c   = 0.1 \npaper_cv   = 0.1 \npaper_rho_0v = 0 \npaper_rho_0c = 0 \npaper_rho_0cv = 0 \npaper_rho_vc = 0 \npaper_rho_vcv = 0 \npaper_rho_ccv = 0 \nsigma    = 0.5 # residual (error) sd (i.e. all variation that the model cannot account for)\n# simulation related\nn_subj  = 100 # number of subjects for each experimental arm (i.e. an experiment with a control and one intervention group has n = 400)\nn_fake  =  5 # number of fake news items \nn_true  =  5 # number of true news items\nn_max_conditions = 4 # maximum number of possible conditions for a single experiment\nn_max_experiments = 4 # maximum number of possible experiments within a single paper\nn_papers = 10 # number of papers in the meta analysis\n```\n:::\n\n\n\n\nWe store a complete list of parameters in a list so that we can call them for functions later.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# complete list of parameters (including some that will be introduced later)\nparameters <- list(\n  # fixed effects\n  beta_0   = -0.5, # intercept (- average response bias )\n  beta_v   = 1, # average sensitivity (d prime) \n  beta_c   = - 0.1, # - delta response bias (i.e. - delta c)\n  beta_cv   = 0.1, # delta sensitivity (i.e. delta d prime)\n  # random effects\n  # subjects\n  subj_0   = 0.1, # by-subject intercept sd\n  subj_v   = 0.1, # by-subject sensitivity (d prime) sd\n  subj_rho_0v = 0, # correlation between intercept (- average response bias) and sensitivity (d prime)\n  # experiments\n  exp_0   = 0.1, # by-experiment intercept sd\n  exp_v   = 0.1, # by-experiment sensitivity (d prime) sd\n  exp_c   = 0.1, # by-experiment - delta response bias (i.e. - delta c) sd\n  exp_cv   = 0.1, # by-experiment delta sensitivity (i.e. delta d prime) sd\n  exp_rho_0v = 0, # correlation between intercept (- average response bias) and sensitivity (d prime)\n  exp_rho_0c = 0, # correlation between intercept and - delta response bias (i.e. - delta c)\n  exp_rho_0cv = 0, # correlation between intercept (- average response bias) and delta sensitivity (i.e. delta d prime)\n  exp_rho_vc = 0, # correlation between sensitivity (d prime) and - delta response bias (i.e. - delta c)\n  exp_rho_vcv = 0, # correlation between sensitivity (d prime) and delta sensitivity (i.e. delta d prime)\n  exp_rho_ccv = 0, # correlation between - delta response bias (i.e. - delta c) and delta sensitivity (i.e. delta d prime)\n  # papers\n  paper_0   = 0.1, # analogous to experiment random effects\n  paper_v   = 0.1, \n  paper_c   = 0.1, \n  paper_cv   = 0.1, \n  paper_rho_0v = 0, \n  paper_rho_0c = 0, \n  paper_rho_0cv = 0, \n  paper_rho_vc = 0, \n  paper_rho_vcv = 0, \n  paper_rho_ccv = 0, \n  sigma    = 0.5, # residual (error) sd (i.e. all variation that the model cannot account for)\n  # simulation related\n  n_subj  = 100, # number of subjects for each experimental arm (i.e. an experiment with a control and one intervention group has n = 200)\n  n_fake  =  5, # number of fake news items \n  n_true  =  5, # number of true news items\n  n_max_conditions = 4, # maximum number of possible conditions for a single experiment\n  n_max_experiments = 4, # maximum number of possible experiments within a single paper\n  n_papers = 10 # number of papers in the meta analysis\n)\n```\n:::\n\n\n\n\n## Simulate a single sample\n\n### Stimuli (news items)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate a sample of items\nn_items <- n_fake + n_true\n\nitems <- data.frame(\n  item_id = seq_len(n_items),\n  veracity = rep(c(\"fake\", \"true\"), c(n_fake, n_true)),\n  # get a numeric version of veracity that is effect-coded (i.e. not 0 vs. 1, \n  # but -0.5 and 0.5)\n  veracity_effect_code = rep(c(-0.5, 0.5), c(n_fake, n_true))\n)\n```\n:::\n\n\n\n\n### Sujects\n\nWe use the function `MASS::mvrnorm` to calculate the variance-covariance matrix between the two by-subject random effects.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate a sample of subjects\n\n# calculate random intercept / random slope covariance\ncovar <- subj_rho_0v * subj_0 * subj_v\n\n# put values into variance-covariance matrix\ncov_mx  <- matrix(\n  c(subj_0^2, covar,\n    covar,   subj_v^2),\n  nrow = 2, byrow = TRUE)\n\n# generate the by-subject random effects\nsubject_rfx <- MASS::mvrnorm(n = n_subj,\n                             mu = c(SU_0 = 0, SU_v = 0),\n                             Sigma = cov_mx)\n\n# combine with subject IDs\nsubjects <- data.frame(subject_id = seq_len(n_subj),\n                       subject_rfx)\n```\n:::\n\n\n\n\nCheck values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(\n  parameter = c(\"subj_0\", \"subj_v\", \"subj_rho_0v\"),\n  value = c(subj_0, subj_v, subj_rho_0v),\n  simulated = c(\n    sd(subjects$SU_0),\n    sd(subjects$SU_v), \n    cor(subjects$SU_0, subjects$SU_v)\n  )\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    parameter value  simulated\n1      subj_0   0.1 0.10321873\n2      subj_v   0.1 0.10044053\n3 subj_rho_0v   0.0 0.02538285\n```\n\n\n:::\n:::\n\n\n\n\n### Trials (Subjects x Stimuli)\n\nWe combine the two data frames `subjects` and `items` we generated. We also draw a residual error for each trial/observation (`e_s` for error term for each combination of subject and stimulus).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cross subject and item IDs; add an error term\n# nrow(.) is the number of rows in the table\ntrials <- crossing(subjects, items)  %>%\n  mutate(e_s = rnorm(nrow(.), mean = 0, sd = sigma))\n```\n:::\n\n\n\n\n### Function\n\nWe put all the previous steps in a function. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set up the custom data simulation function\ndraw_sample <- function(\n# fixed effects\n  beta_0,\n  beta_v,\n  beta_c,\n  beta_cv,\n  # random effects\n  subj_0,\n  subj_v,\n  subj_rho_0v,\n  # simulation related\n  n_subj,\n  n_fake,\n  n_true,\n  sigma,\n  ...  # This allows additional parameters to be ignored\n) { \n  \n  # simulate a sample of items\n  n_items <- n_fake + n_true\n  \n  items <- data.frame(\n    item_id = seq_len(n_items),\n    veracity = rep(c(\"fake\", \"true\"), c(n_fake, n_true)),\n    # get a numeric version of veracity that is effect-coded (i.e. not 0 vs. 1, \n    # but -0.5 and 0.5)\n    veracity_effect_code = rep(c(-0.5, 0.5), c(n_fake, n_true))\n  )\n  \n  # simulate a sample of subjects\n  \n  # calculate random intercept / random slope covariance\n  covar <- subj_rho_0v * subj_0 * subj_v\n  \n  # put values into variance-covariance matrix\n  cov_mx  <- matrix(\n    c(subj_0^2, covar,\n      covar,   subj_v^2),\n    nrow = 2, byrow = TRUE)\n  \n  # generate the by-subject random effects\n  subject_rfx <- MASS::mvrnorm(n = n_subj,\n                               mu = c(SU_0 = 0, SU_v = 0),\n                               Sigma = cov_mx)\n  \n  # combine with subject IDs\n  subjects <- data.frame(subject_id = seq_len(n_subj),\n                         subject_rfx)\n  \n  # cross subject and item IDs and calculate accuracy\n  crossing(subjects, items)  %>%\n    mutate(e_s = rnorm(nrow(.), mean = 0, sd = sigma))\n}\n\n# test function\n# test <- do.call(draw_sample, parameters)\n```\n:::\n\n\n\n\n\n## Simulate an experiment\n\nWe know how to generate a sample, which corresponds to all participants assigned to the same experimental condition. However, an experiment consists of several conditions, and thus several samples. \n\nFor example, we might have three conditions, one control group, and two intervention groups.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_conditions <- 3\n\nn_interventions <- n_conditions - 1 # we assume always one control group\n\n# draw control condition\ncontrol <- do.call(draw_sample, parameters) %>% \n  mutate(condition = \"control\")\n\n# draw interventions\ninterventions <-  1:n_interventions %>%\n    map_dfr(function(x) {\n\n      # To keep track of progress\n      print(paste(\"drawing intervention number \", x))\n      \n      single_intervention <- do.call(draw_sample, parameters) %>% \n        mutate(condition = \"intervention\", \n               intervention_id = x)\n      \n      return(single_intervention)\n    })\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# combine control and interventions data\nexperiment <- bind_rows(control, interventions)\n```\n:::\n\n\n\n\n### Function\n\nIn our function, we allow the number of conditions to vary. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate an experiment\ndraw_experiment <- function(n_max_conditions = NULL, ...) {\n  \n  # generate random number of conditions\n  possible_n_conditions <- seq(from = 2, to = n_max_conditions, by = 1)\n  n_conditions <- sample(possible_n_conditions, size = 1)\n  \n  n_interventions <- n_conditions - 1 # we assume always one control group\n  \n  # draw control condition\n  control <- draw_sample(...) %>% \n    mutate(condition = \"control\")\n  \n# draw interventions\ninterventions <-  1:n_interventions %>%\n    map_dfr(function(x) {\n\n      # To keep track of progress\n      print(paste(\"drawing intervention number \", x))\n      \n      single_intervention <- draw_sample(...) %>% \n        mutate(condition = \"intervention\", \n               intervention_id = x)\n      \n      return(single_intervention)\n    })\n\n# combine control and interventions data\nexperiment <- bind_rows(control, interventions)\n\n} \n# test  \n# test <- do.call(draw_experiment, parameters)\n```\n:::\n\n\n\n\n## Simulate various experiments (within a single paper)\n\nA single paper can contain multiple experiments. For example, we might have three experiments. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_experiments <- 3\n\n# draw experiments\nexperiments <-  1:n_experiments %>%\n    map_dfr(function(x) {\n\n      # To keep track of progress\n      print(paste(\"drawing experiment number \", x))\n      \n      single_experiment <- do.call(draw_experiment, parameters) %>% \n        mutate(experiment_id = x)\n      \n      return(single_experiment)\n    })\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n```\n\n\n:::\n\n```{.r .cell-code}\nexperiments %>% \n  group_by(experiment_id, intervention_id) %>% \n  count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 × 3\n# Groups:   experiment_id, intervention_id [9]\n  experiment_id intervention_id     n\n          <int>           <int> <int>\n1             1               1  1000\n2             1               2  1000\n3             1               3  1000\n4             1              NA  1000\n5             2               1  1000\n6             2               2  1000\n7             2              NA  1000\n8             3               1  1000\n9             3              NA  1000\n```\n\n\n:::\n:::\n\n\n\n\nWe assume experiments to have random effects. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate covariances\ncovar_0v_exp <- exp_rho_0v * exp_0 * exp_v\ncovar_0c_exp <- exp_rho_0c * exp_0 * exp_c\ncovar_0cv_exp <- exp_rho_0cv * exp_0 * exp_cv\ncovar_vc_exp <- exp_rho_vc * exp_v * exp_c\ncovar_vcv_exp <- exp_rho_vcv * exp_v * exp_cv\ncovar_cc_exp <- exp_rho_ccv * exp_c * exp_cv\n\n# Create the variance-covariance matrix\ncov_mx_exp <- matrix(\n  c(exp_0^2, covar_0v_exp, covar_0c_exp, covar_0cv_exp,\n    covar_0v_exp, exp_v^2, covar_vc_exp, covar_vcv_exp,\n    covar_0c_exp, covar_vc_exp, exp_c^2, covar_cc_exp,\n    covar_0cv_exp, covar_vcv_exp, covar_cc_exp, exp_cv^2),\n  nrow = 4, byrow = TRUE\n)\n\n# Generate the by-experiment random effects\nexp_rfx <- MASS::mvrnorm(n = n_experiments,\n                         mu = c(EXP_0 = 0, EXP_v = 0, EXP_c = 0, EXP_cv = 0),\n                         Sigma = cov_mx_exp)\n\n# Check the value of n_experiments\nif (n_experiments == 1) {\n  # Reshape to wide format\n  exp_rfx <- data.frame(exp_rfx) %>%\n    mutate(effect = rownames(.)) %>% \n    pivot_wider(names_from = effect, values_from = \"exp_rfx\")\n}\n\n# Combine with experiment IDs\nexp_rfx <- data.frame(experiment_id = seq_len(n_experiments), exp_rfx)\n\n# add random effects to experiment data\nexperiments <- left_join(experiments, exp_rfx, by = \"experiment_id\")\n```\n:::\n\n\n\n\n### Function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate multiple experiments\ndraw_multiple_experiments <- function(\n    n_max_experiments, \n    exp_0, # by-experiment intercept sd\n    exp_v, # by-experiment sensitivity (d prime) sd\n    exp_c, # by-experiment - delta response bias (i.e. - delta c) sd\n    exp_cv, # by-experiment delta sensitivity (i.e. delta d prime) sd\n    exp_rho_0v, # correlation between intercept (- average response bias) and sensitivity (d prime)\n    exp_rho_0c, # correlation between intercept and - delta response bias (i.e. - delta c)\n    exp_rho_0cv, # correlation between intercept (- average response bias) and delta sensitivity (i.e. delta d prime)\n    exp_rho_vc, # correlation between sensitivity (d prime) and - delta response bias (i.e. - delta c)\n    exp_rho_vcv, # correlation between sensitivity (d prime) and delta sensitivity (i.e. delta d prime)\n    exp_rho_ccv, # correlation between - delta response bias (i.e. - delta c) and delta sensitivity (i.e. delta d prime)\n    ...) {\n  \n  # generate random number of experiments\n  possible_n_experiments <- seq(from = 1, to = n_max_experiments, by = 1)\n  n_experiments <- sample(possible_n_experiments, size = 1)\n  \n  # draw experiments\n  experiments <-  1:n_experiments %>%\n    map_dfr(function(x) {\n      \n      # To keep track of progress\n      print(paste(\"drawing experiment number \", x))\n      \n      single_experiment <- draw_experiment(...) %>% \n        mutate(experiment_id = x)\n      \n      return(single_experiment)\n    })\n  \n  # Calculate covariances\n  covar_0v_exp <- exp_rho_0v * exp_0 * exp_v\n  covar_0c_exp <- exp_rho_0c * exp_0 * exp_c\n  covar_0cv_exp <- exp_rho_0cv * exp_0 * exp_cv\n  covar_vc_exp <- exp_rho_vc * exp_v * exp_c\n  covar_vcv_exp <- exp_rho_vcv * exp_v * exp_cv\n  covar_cc_exp <- exp_rho_ccv * exp_c * exp_cv\n  \n  # Create the variance-covariance matrix\n  cov_mx_exp <- matrix(\n    c(exp_0^2, covar_0v_exp, covar_0c_exp, covar_0cv_exp,\n      covar_0v_exp, exp_v^2, covar_vc_exp, covar_vcv_exp,\n      covar_0c_exp, covar_vc_exp, exp_c^2, covar_cc_exp,\n      covar_0cv_exp, covar_vcv_exp, covar_cc_exp, exp_cv^2),\n    nrow = 4, byrow = TRUE\n  )\n  \n  # Generate the by-experiment random effects\n  exp_rfx <- MASS::mvrnorm(n = n_experiments,\n                           mu = c(EXP_0 = 0, EXP_v = 0, EXP_c = 0, EXP_cv = 0),\n                           Sigma = cov_mx_exp)\n  \n  # Check the value of n_experiments\n  if (n_experiments == 1) {\n    # if n == 1, mvnorm seems to return a vector, which data.frame then turns \n    # into long format data (instead of wide-format when n_experiments > 1)\n    # Reshape to wide format\n    exp_rfx <- data.frame(exp_rfx) %>%\n      mutate(effect = rownames(.)) %>% \n      pivot_wider(names_from = effect, values_from = \"exp_rfx\")\n  }\n  \n  # Combine with experiment IDs\n  exp_rfx <- data.frame(experiment_id = seq_len(n_experiments), exp_rfx)\n  \n  # add random effects to experiment data\n  experiments <- left_join(experiments, exp_rfx, by = \"experiment_id\")\n  \n  return(experiments)\n}\n\n# test \n# test <- do.call(draw_multiple_experiments, parameters)\n```\n:::\n\n\n\n\n## Simulate various papers\n\nFinally, we have various papers. As for experiments, we expect random effects for papers (because of authors, country, time, etc.). \n\nFor example, we might have 20 papers. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_papers <- 20\n\n# draw papers\npapers <-  1:n_papers %>%\n    map_dfr(function(x) {\n\n      # To keep track of progress\n      print(paste(\"drawing paper number \", x))\n      \n      single_paper <- do.call(draw_multiple_experiments, parameters) %>% \n        mutate(paper_id = x)\n      \n      return(single_paper)\n    })\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"drawing paper number  1\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  2\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  3\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  4\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  5\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing paper number  6\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  7\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  8\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  9\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  10\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  11\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  12\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  4\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  13\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  4\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  14\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  15\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  16\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing paper number  17\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  18\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  4\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  19\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  20\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n```\n\n\n:::\n:::\n\n\n\n\nAnd the random effects random effects. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate covariances\ncovar_0v_paper <- paper_rho_0v * paper_0 * paper_v\ncovar_0c_paper <- paper_rho_0c * paper_0 * paper_c\ncovar_0cv_paper <- paper_rho_0cv * paper_0 * paper_cv\ncovar_vc_paper <- paper_rho_vc * paper_v * paper_c\ncovar_vcv_paper <- paper_rho_vcv * paper_v * paper_cv\ncovar_cc_paper <- paper_rho_ccv * paper_c * paper_cv\n\n# Create the variance-covariance matrix\ncov_mx_paper <- matrix(\n  c(paper_0^2, covar_0v_paper, covar_0c_paper, covar_0cv_paper,\n    covar_0v_paper, paper_v^2, covar_vc_paper, covar_vcv_paper,\n    covar_0c_paper, covar_vc_paper, paper_c^2, covar_cc_paper,\n    covar_0cv_paper, covar_vcv_paper, covar_cc_paper, paper_cv^2),\n  nrow = 4, byrow = TRUE\n)\n\n# Generate the by-paper random effects\npaper_rfx <- MASS::mvrnorm(n = n_papers,\n                         mu = c(PAP_0 = 0, PAP_v = 0, PAP_c = 0, PAP_cv = 0),\n                         Sigma = cov_mx_paper)\n\n# Combine with paper IDs\npaper_rfx <- data.frame(paper_id = seq_len(n_papers), paper_rfx)\n\n# add random effects to paper data\npapers <- left_join(papers, paper_rfx)\n```\n:::\n\n\n\n\nFinally, we want to be able to uniquely identify participants and experiments across papers (for now, there is a participant labeled \"1\" in each experiment, and there is an experiment \"1\" in each paper).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npapers <- papers %>% \n  mutate(    \n    # unique experiment identifier\n    unique_experiment_id = paste(paper_id, experiment_id, sep = \"_\"), \n    # unique participant identifier\n    unique_subject_id = paste0(paper_id, \"_\", experiment_id, intervention_id, \"_\", subject_id), \n    # unique intervention identifier\n    unique_intervention_id = paste(paper_id, experiment_id, intervention_id, sep = \"_\"))\n```\n:::\n\n\n\n\n### Function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate papers\ndraw_papers <- function(\n    paper_0, # analogous to experiment random effects\n    paper_v,\n    paper_c,\n    paper_cv,\n    paper_rho_0v,\n    paper_rho_0c,\n    paper_rho_0cv,\n    paper_rho_vc,\n    paper_rho_vcv, \n    paper_rho_ccv,\n    n_papers = 10, # number of papers in the meta analysis\n    ...) {\n  \n  # draw papers\n  papers <-  1:n_papers %>%\n    map_dfr(function(x) {\n      \n      # To keep track of progress\n      print(paste(\"drawing paper number \", x))\n      \n      single_paper <- do.call(draw_multiple_experiments, parameters) %>% \n        mutate(paper_id = x)\n      \n      return(single_paper)\n    })\n  \n  # Calculate covariances\n  covar_0v_paper <- paper_rho_0v * paper_0 * paper_v\n  covar_0c_paper <- paper_rho_0c * paper_0 * paper_c\n  covar_0cv_paper <- paper_rho_0cv * paper_0 * paper_cv\n  covar_vc_paper <- paper_rho_vc * paper_v * paper_c\n  covar_vcv_paper <- paper_rho_vcv * paper_v * paper_cv\n  covar_cc_paper <- paper_rho_ccv * paper_c * paper_cv\n  \n  # Create the variance-covariance matrix\n  cov_mx_paper <- matrix(\n    c(paper_0^2, covar_0v_paper, covar_0c_paper, covar_0cv_paper,\n      covar_0v_paper, paper_v^2, covar_vc_paper, covar_vcv_paper,\n      covar_0c_paper, covar_vc_paper, paper_c^2, covar_cc_paper,\n      covar_0cv_paper, covar_vcv_paper, covar_cc_paper, paper_cv^2),\n    nrow = 4, byrow = TRUE\n  )\n  \n  # Generate the by-paper random effects\n  paper_rfx <- MASS::mvrnorm(n = n_papers,\n                             mu = c(PAP_0 = 0, PAP_v = 0, PAP_c = 0, PAP_cv = 0),\n                             Sigma = cov_mx_paper)\n  \n  # Combine with paper IDs\n  paper_rfx <- data.frame(paper_id = seq_len(n_papers), paper_rfx)\n  \n  # add random effects to paper data\n  papers <- left_join(papers, paper_rfx) %>% \n  mutate(    \n    # unique experiment identifier\n    unique_experiment_id = paste(paper_id, experiment_id, sep = \"_\"), \n    # unique participant identifier\n    unique_subject_id = paste0(paper_id, \"_\", experiment_id, intervention_id, \"_\", subject_id), \n    # unique intervention identifier\n    unique_intervention_id = paste(paper_id, experiment_id, intervention_id, sep = \"_\"))\n}\n\n# test \n# test <- do.call(draw_papers, parameters)\n```\n:::\n\n\n\n\n## Model accuracy ratings\n\nAt this point, we have simulated data with all necessary information to generate accuracy ratings, according to our model. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate accuracy\nfinal_data <- papers %>% \n  mutate(\n    # make numeric helper variables using deviation coding\n    veracity_numeric = ifelse(veracity == \"true\", 0.5, -0.5),\n    condition_numeric = ifelse(condition == \"intervention\",  0.5, -0.5),\n    # calculate z-value accuracy\n    accuracy_z_value = \n      (beta_0 + SU_0 + EXP_0 + PAP_0) +\n      (beta_v + SU_v + EXP_v + PAP_v)*veracity_numeric +\n      (beta_c + EXP_c + PAP_c )*condition_numeric+\n      (beta_cv + EXP_cv + PAP_cv)*(condition_numeric*veracity_numeric) +\n      e_s,\n    # use the probit function (i.e. cumulative distribution function of the standard normal distribution)\n    # to optain probabilities from the z-values\n    accuracy_probability = pnorm(accuracy_z_value), \n    # generate a binary accuracy response by sampling from a bernoulli distribution\n    # (i.e. binomial distribution with one trial)\n    accuracy = rbinom(nrow(.), 1, accuracy_probability)\n  ) %>% \n  # remove random effect variables\n  select(-matches(\"SU|EXP|PAP\", ignore.case = FALSE))\n```\n:::\n\n\n\n\n#### Function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate accuracy outcomes\ncalculate_accuracy <- function(\n    data, \n    # fixed effects\n    beta_0, # intercept (- average response bias )\n    beta_v, # average sensitivity (d prime) \n    beta_c, # - delta response bias (i.e. - delta c)\n    beta_cv, # delta sensitivity (i.e. delta d prime)\n    ...\n    ){\n    \n    data <- data %>% \n    mutate(\n      # make numeric helper variables using deviation coding\n      veracity_numeric = ifelse(veracity == \"true\", 0.5, -0.5),\n      condition_numeric = ifelse(condition == \"intervention\",  0.5, -0.5),\n      # calculate z-value accuracy\n      accuracy_z_value = \n        (beta_0 + SU_0 + EXP_0 + PAP_0) +\n        (beta_v + SU_v + EXP_v + PAP_v)*veracity_numeric +\n        (beta_c + EXP_c + PAP_c )*condition_numeric+\n        (beta_cv + EXP_cv + PAP_cv)*(condition_numeric*veracity_numeric) +\n        e_s,\n      # use the probit function (i.e. cumulative distribution function of the standard normal distribution)\n      # to optain probabilities from the z-values\n      accuracy_probability = pnorm(accuracy_z_value), \n      # generate a binary accuracy response by sampling from a bernoulli distribution\n      # (i.e. binomial distribution with one trial)\n      accuracy = rbinom(nrow(.), 1, accuracy_probability)\n    ) %>% \n    # remove random effect variables\n    select(-matches(\"SU|EXP|PAP\", ignore.case = FALSE))\n}\n\n# test\n# test <- calculate_accuracy(papers)\n```\n:::\n\n\n\n\n# Simulation of a single data set for pre-registration\n\nWe to use all the previous functions in a single simulation, we combine the `draw_papers()` and `call_accuracy()` functions. We call the final function `simulate_data()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# final data simulation function\nsimulate_data <- function(...) {\n  papers <- draw_papers(...)\n  \n  final_data <- calculate_accuracy(papers, ...)\n  \n  return(final_data)\n}\n```\n:::\n\n\n\n\nWe can then simulate our participant-level data, based on the previously set parameters.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- do.call(simulate_data, parameters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"drawing paper number  1\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  2\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  3\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing paper number  4\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  5\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  6\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing paper number  7\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  8\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing paper number  9\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing paper number  10\"\n[1] \"drawing experiment number  1\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing experiment number  2\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing experiment number  3\"\n[1] \"drawing intervention number  1\"\n[1] \"drawing intervention number  2\"\n[1] \"drawing intervention number  3\"\n```\n\n\n:::\n:::\n\n\n\n\n## Add moderators\n\n### Within-experiment moderator\n\nThe most important within-participant moderator we will look at is political concordance. Let's assume that half our our news item ratings were politically concordant and half not.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add some other variables for demonstration purpose\ndata <- data %>% \n  mutate(\n    # political concordance\n    political_concordance = ifelse(item_id %% 2 == 0, \"concordant\", \"discordant\"),\n    # add a deviation coded version for the political concordance variable\n    concordance_numeric = ifelse(political_concordance == \"discordant\", \n                                 -0.5, ifelse(!is.na(political_concordance), \n                                              0.5, \n                                              NA)\n    )\n  ) \n\n# check\n# data %>% \n#   select(concordance_numeric, political_concordance)\n```\n:::\n\n\n\n\nA second moderator that varies within experiments, but between participants, is age. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# randomly assing intervention types\nparticipant_ages <- data %>%\n# Get unique combinations of unique_experiment_id and condition\n  distinct(unique_subject_id) %>% \n  mutate(\n    # Sample from intervention types only when condition is not \"control\"\n    age = sample(seq(18:70), size = nrow(.), replace = TRUE)\n  )\n\n# add intervention types to data\ndata <- left_join(data, participant_ages)\n```\n:::\n\n\n\n\n### Between-experiment moderator\n\nThe most important between-experiment moderator we will look at is intervention type. To illustrate, let's assume that all used interventions can be classified as one out of three broad categories of interventions (let's call them \"literacy tips\", \"priming\", \"warning labels\").\n\nSometimes, within the same experiment, researchers might have tested different interventions. Since we will likely have to deal with that case, we should simulate it here. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# randomly assing intervention types\nintervention_types <- data %>%\n# Get unique combinations of unique_experiment_id and condition\n  distinct(unique_intervention_id, condition) %>% \n  mutate(\n    # Sample from intervention types only when condition is not \"control\"\n    intervention_type = ifelse(condition != \"control\",\n                               sample(c(\"literacy tips\", \"priming\", \"warning labels\"), \n                                      size = sum(condition != \"control\"), \n                                      replace = TRUE),\n                               \"control\")\n  )\n\n# add intervention types to data\ndata <- left_join(data, intervention_types)\n```\n:::\n\n\n\n\n## Store simulated data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# store individual level data\nfilename <- \"../data/simulations/individual_level.csv\" \nwrite_csv(data, filename)\n```\n:::\n\n\n\n\n# Sensitivity analysis and parameter recovery\n\nWe will run a kind of sensitivity analysis. \n\nFor the simulation, we--conservatively--assumed that the meta-analysis sample will consist of 10 papers. We assumed that each paper has between 1 and 4 experiments, and each experiment can have between two and four experimental arms (one of which is always the control condition). For each experimental arm, we assumed a sample size of 100 participants. The number of experiments per paper and arms per experiments was chosen randomly for each study. We further assumed that participants always saw 5 true and 5 false news. For details about other parameter assumptions, see the parameter list specified above. Although our final sample of papers will probably have properties quite different from what we assumed here, we believe these assumptions are rather conservative. \n\nIn our simulations, we vary the values for the true effect sizes for d'prime and c in the data. For each combination of effect sizes, we run 100 iterations, i.e. 100 times we generate a different sample of 10 papers, and run our meta-analysis on that sample. The aim of the sensitivity analysis consists in checking how many of these 100 meta-analyses find a significant effect. The share of analyses that detect the true effect is the statistical power.\n\nInstead of only checking whether our models find a significant effect or not, we also descriptively check how well our model estimates recover the data generating parameters. \n\n## Estimator\n\nWe start by defining the model we use to estimate our effects, and select the outcomes of interest. We will run a participant-level meta analysis using a two-stage approach: First, for each experiment, we calculate the above mixed model. The resulting estimates are our effect sizes. Second, we run a meta analysis on these effect sizes.\n\n### Define the model\n\nWe first write a function for calculating the model for each experiment.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate model function\ncalculate_SDT_model <- function(data) {\n  \n  time <- system.time({\n    model <- glmer(accuracy ~ veracity_numeric + condition_numeric + \n                     veracity_numeric*condition_numeric +\n                     (1 + veracity_numeric | unique_subject_id),\n                   data = data, \n                   family = binomial(link = \"probit\")\n    )\n  })\n  \n  time <- round(time[3]/60, digits = 2)\n  \n  # get a tidy version\n  model <- tidy(model, conf.int = TRUE) %>% \n    # add time\n    mutate(time_minutes = time)\n  \n  # give nicer names in SDT terminology to estimates (! and reverse estimates for response bias !)\n  model <- model %>% \n    mutate(\n      # reverse c and delta c estimates\n      estimate = ifelse(term == \"(Intercept)\" | term == \"condition_numeric\", \n                        -1*estimate, estimate),\n      term = case_when(term == \"(Intercept)\" ~ \"average response bias (c)\", \n                       term == \"veracity_numeric\" ~ \"average sensitivity (d')\", \n                       term == \"condition_numeric\" ~ \"delta c\",\n                       term == \"veracity_numeric:condition_numeric\" ~ \"delta d'\",\n                       TRUE ~ term\n      ),\n      sampling_variance = std.error^2\n    ) \n  \n  return(model)\n  \n}\n# test\n# mixed_model <- calculate_SDT_model(data %>% filter(unique_experiment_id == \"1_1\"))\n# mixed_model\n```\n:::\n\n\n\n\n### Run the loop\n\nWe then run a for loop, to calculate one model per experiment and store the results in a common data frame.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loop over experiments\nrun_SDT_model_loop <- function(data){\n  \n  # make a vector with all unique experiment ids\n  experiments <- data %>% \n    distinct(unique_experiment_id) %>% \n    # slice(1:3) %>% # to test loop\n    pull()\n  \n  time <- system.time({\n    \n    # run one model per experiment and store the results in a common data frame\n    results <- experiments %>%\n      map_dfr(function(x) {\n        \n        # restrict data to only the respective experiment\n        experiment <- data %>% filter(unique_experiment_id == x)\n        \n        # extract paper id\n        paper_id <- unique(experiment$paper_id)\n        \n        # To keep track of progress\n        print(paste(\"calculating model for experiment \", x))\n        \n        model_experiment <- calculate_SDT_model(experiment) %>%\n          mutate(unique_experiment_id = x,\n                 paper_id = paper_id)\n        \n        return(model_experiment)\n      })\n  })\n  \n  print(paste(\"Elapsed time: \", round(time[3]/60, digits = 2), \" minutes\"))\n  \n  return(results)\n}\n\n\n# test\n# experiment_ids_to_test <- data %>% distinct(unique_experiment_id) %>% slice(1:5) %>% pull()\n# test <- run_SDT_model_loop(data%>% filter(unique_experiment_id %in% experiment_ids_to_test))\n# test\n```\n:::\n\n\n\n\n### Run the meta-analysis\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate meta models\ncalculate_meta_model <- function(data, yi, vi, robust = TRUE) {\n  \n  # provide metafor compatible names\n  metafor_data <- data %>% \n    rename(yi = {{yi}}, \n           vi = {{vi}})\n  \n  # Multilevel random effect model for accuracy\n  model <-  metafor::rma.mv(yi, vi, random = ~ 1 | paper_id / unique_experiment_id, \n                            data = metafor_data)\n  \n  return(model)\n  \n  if(robust == TRUE) {\n    # with robust standard errors clustered at the paper level \n    robust_model <- robust(model, cluster = data$paper_id)\n    \n    return(robust_model)\n  }\n}\n# test \n\n# generate some model output\n# experiment_ids_to_test <- data %>% distinct(unique_experiment_id) %>% slice(1:5) %>% pull()\n# test_model_output <- run_SDT_model_loop(data%>% filter(unique_experiment_id %in% experiment_ids_to_test))\n# \n# # model for delta dprime\n# delta_dprime <- calculate_meta_model(data = test_model_output  %>% \n#                                        filter(term == \"delta d'\"), yi = estimate, \n#                                      vi = sampling_variance, robust = TRUE) %>% \n#   tidy() %>% \n#   mutate(term = ifelse(term == \"overall\", \"delta d'\", NA))\n# \n# # model for delta c\n# delta_c <- calculate_meta_model(data = test_model_output  %>% \n#                                   filter(term == \"delta c\"), yi = estimate, \n#                                 vi = sampling_variance, robust = TRUE) %>% \n#   tidy() %>% \n#   mutate(term = ifelse(term == \"overall\", \"delta c\", NA))\n```\n:::\n\n\n\n\nWe combine all these analysis steps in a single estimate function. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# final function for running all models \nget_meta_estimates <- function(data){\n  \n  # generate outcome data for all experiments\n  outcome_data <- run_SDT_model_loop(data)\n  \n  # calculate meta model for delta dprime\n  delta_dprime <- calculate_meta_model(data = outcome_data  %>% \n                                         filter(term == \"delta d'\"), \n                                       yi = estimate, \n                                       vi = sampling_variance, \n                                       robust = TRUE) %>% \n    tidy() %>% \n    mutate(term = ifelse(term == \"overall\", \"delta d'\", NA))\n  \n  # calculate meta model for delta c\n  delta_c <- calculate_meta_model(data = outcome_data  %>% \n                                    filter(term == \"delta c\"), \n                                  yi = estimate, \n                                  vi = sampling_variance, \n                                  robust = TRUE) %>% \n    tidy() %>% \n    mutate(term = ifelse(term == \"overall\", \"delta c\", NA))\n  \n  estimates <- bind_rows(delta_dprime, delta_c)\n  \n  return(estimates)\n  \n}\n\n# test \n\n# reduce data to some experiments only\n# experiment_ids_to_test <- data %>% distinct(unique_experiment_id) %>% slice(1:5) %>% pull()\n# \n# result <- get_meta_estimates(data %>% filter(unique_experiment_id %in% experiment_ids_to_test))\n# result\n```\n:::\n\n\n\n\n## Run iterations\n\nFor each combination of effect sizes, we run several iterations, so that we can get an impression of how well different meta-analytic samples recover the parameters. For each iteration, the function first generates a set of studies to run the meta-analysis on, and then runs the meta-analysis. The results will be stored in a single data frame, in which iterations are labeled.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# repeat the process and store some information on it (e.g. time taken, number of iteration)\niterate <- function(iterations, ...) {\n  \n  # create data frame with model results for generated samples\n  result <- 1:iterations %>%\n    purrr::map_df(function(x) {\n      \n      # Measure time for each iteration\n      iteration_time <- system.time({\n        # generate data\n        participant_level_data <- simulate_data(...)\n        \n        # run models on the data\n        estimates <- get_meta_estimates(participant_level_data)\n      })\n      \n      # Add iteration number and time in minutes to estimates\n      estimates <- estimates %>%\n        mutate(iteration = x,\n               time_taken_minutes = iteration_time[3] / 60)  # Convert time to minutes\n      \n      # To keep track of progress\n      if (x %% 2 == 0) {print(paste(\"iteration number \", x))}\n      \n      return(estimates)\n    })\n  \n  return(result)\n}\n# test\n# note that even for just 10 meta-analyses, this takes quite a while, ~1min per iteration\n# test <- do.call(iterate, c(parameters, list(iterations = 4)))\n# \n# ggplot(test %>% filter(term == \"delta d'\"), aes(x = estimate)) +\n#   geom_histogram() +\n#   geom_vline(xintercept = parameters$beta_cv, linetype = \"dotted\", color = \"black\")\n# \n# ggplot(test %>% filter(term == \"delta c\"), aes(x = estimate)) +\n#   geom_histogram() +\n#   geom_vline(xintercept = -parameters$beta_c, linetype = \"dotted\", color = \"black\")\n```\n:::\n\n\n\n\n# Sensitivity analysis\n\nFor a start, we will have three different effect sizes (small = 0.1, medium = 0.5, large = 1) and run 100 meta-analyses on each combination. We will check calculate the statistical power we have for each effect.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run sensitivity analysis\nsensitivity_analysis <- function(file_name, effect_sizes_to_try, iterations, ...) {\n  \n  # make full file name\n  full_file_name <- paste0(\"../data/simulations/\", file_name)\n  \n  # only run analysis if a file with that name does not yet exists\n  if (!file.exists(full_file_name)) {\n    \n    sensitivity_data <- pmap_df(effect_sizes_to_try, function(delta_d_prime, delta_c) {\n      \n      # To keep track of progress\n      print(paste(\"test for delta c = \", delta_c, \"; delta d' = \", delta_d_prime))\n      \n      # calculate the results for a specific combination of parameters\n      combination_result <-  iterate(iterations = iterations, \n                                     beta_cv = delta_d_prime, \n                                     # make sure to reverse the data generating parameter for response bias\n                                     beta_c = -delta_c, \n                                     ...\n                                     )\n      \n      # add combination of parameters to data frame\n      combination_result <- combination_result %>% \n        mutate(parameter_delta_d_prime = delta_d_prime, \n               parameter_delta_c = delta_c)\n      \n    })\n    \n    write_csv(sensitivity_data, full_file_name)\n    \n    return(sensitivity_data)\n  }\n}\n\n# test\n\n# the code below tests the function content, not the function itself\n\n# # make a data frame with sample sizes\n# effect_sizes_to_try <- crossing(delta_d_prime = c(0.1, 1),\n#                                 # reverse response bias estimates\n#                                 delta_c = c(-0.1, -1))\n# \n# # Remove initial parameters from list since we want to replace it\n# # with the respective effect size combination every time.\n# parameters[[\"beta_cv\"]] <- NULL\n# parameters[[\"beta_c\"]] <- NULL\n# \n# sensitivity_data <- pmap_df(effect_sizes_to_try, function(delta_d_prime, delta_c) {\n#   \n#   # To keep track of progress\n#   print(paste(\"test for delta c = \", delta_c, \"; delta d' = \", delta_d_prime))\n#   \n#   # calculate the results for a specific combination of parameters\n#   combination_result <-  do.call(iterate, \n#                                  c(parameters,\n#                                    list(beta_cv = delta_d_prime, \n#                                         # make sure to reverse the data generating parameter for response bias\n#                                         beta_c = -delta_c), \n#                                    list(iterations = 2)\n#                                  )\n#   ) \n#   \n#   # add combination of parameters to data frame\n#   combination_result <- combination_result %>% \n#     mutate(parameter_delta_d_prime = delta_d_prime, \n#            parameter_delta_c = delta_c)\n#   \n# })\n```\n:::\n\n\n\n\nWe first make changes to the parameter list. Since we are now varying the effect sizes of delta d' and delta c, we remove them from the orgininal parameter list. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove initial parameters from list since we want to replace it\n# with the respective effect size combination every time.\nparameters[[\"beta_cv\"]] <- NULL\nparameters[[\"beta_c\"]] <- NULL\n```\n:::\n\n\n\n\nWe can then run the sensitivity analysis. Note that while we could feed the whole data frame of `effect_sizes_to_try` into the function, this would take very long. For each pair of effect sizes (i.e. one row in the data frame), the model takes approx. half a minute per iteration on my machine. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run sensitivity analysis\n\n# you could just run this, but it would take reaaaally long\n# effect_sizes_to_try <- crossing(delta_d_prime = c(0.2, 0.5, 0.8),\n#                                 delta_c = c(0.2, 0.5, 0.8))\n# \n# do.call(sensitivity_analysis, c(parameters, \n#                                 list(file_name = \"sensitivity_analysis.csv\", \n#                                      effect_sizes_to_try = effect_sizes_to_try, \n#                                      iterations = 2)\n# )\n#                 )\n# \n# sensitivity_data <- read_csv(\"data/sensitivity_analysis.csv\")\n```\n:::\n\n\n\n\nSince I'm running this code locally on my computer, I have two different solutions. The first is to run the code in several chunks, exporting a each data frame and appending it to a common result data frame. To do this, we need to slightly modify the function from before. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# modified function to run the simulation chunk by chunk\n# sensitivity_analysis <- function(file_name, effect_sizes_to_try, iterations, ...) {\n#   \n#   sensitivity_data <- pmap_df(effect_sizes_to_try, function(delta_d_prime, delta_c) {\n#     \n#     # To keep track of progress\n#     print(paste(\"test for delta c = \", delta_c, \"; delta d' = \", delta_d_prime))\n#     \n#     # calculate the results for a specific combination of parameters\n#     combination_result <-  iterate(iterations = iterations, \n#                                    beta_cv = delta_d_prime, \n#                                    # make sure to reverse the data generating parameter for response bias\n#                                    beta_c = -delta_c, \n#                                    ...\n#     )\n#     \n#     # add combination of parameters to data frame\n#     combination_result <- combination_result %>% \n#       mutate(parameter_delta_d_prime = delta_d_prime, \n#              parameter_delta_c = delta_c)\n#     \n#   })\n#   \n#   # make full file name\n#   full_file_name <- paste0(\"data/simulations/\", file_name)\n#   \n#   # Check if the CSV file already exists\n#   if (file.exists(full_file_name)) {\n#     # Append to the existing CSV\n#     write_csv(sensitivity_data, full_file_name, append = TRUE)\n#   } else {\n#     # Write a new CSV file if it doesn't exist\n#     write_csv(sensitivity_data, full_file_name)\n#   }\n#   \n#   return(sensitivity_data)\n#   \n# }\n# \n# # check current combinations\n# sensitivity_data <- read_csv(\"data/simulations/sensitivity_analysis.csv\")\n# sensitivity_data %>% distinct(parameter_delta_c, parameter_delta_d_prime)\n# \n# # run sensitivity analysis chunk by chunk\n# \n# effect_sizes_to_try <- crossing(delta_d_prime = c(0.1, 0.5, 1),\n#                                 delta_c = c(0.1, 0.5, 1))\n# \n# do.call(sensitivity_analysis, c(parameters, \n#                                 list(file_name = \"sensitivity_analysis.csv\", \n#                                      effect_sizes_to_try = effect_sizes_to_try %>% \n#                                        # modify this for new analyses\n#                                        slice(1)\n#                                        , \n#                                      iterations = 2)\n# )\n#                 )\n# \n# sensitivity_data <- read_csv(\"data/simulations/sensitivity_analysis.csv\")\n```\n:::\n\n\n\n\nThe second option, which I have used for our project, is to run the simulation based on an R script in the console. This way, R can run the simulation in the background, while you can use the computer as normal (given that the computations are not too heavy for your computer to handle it all at the same time). To do so, we first copy all the function from this .qmd file to a separate .R script, which we call `sensitivity_simulation.R`. \n\nWe then run this script in the terminal (`Rscript sensitivity_simulation.R`), by making sure to specify the correct project working directory (`cd YOUR/DIRECTORY`). \n\nIf you do this, make sure to not let your computer go to sleep, e.g. by using ['caffeinate'](https://www.theapplegeek.co.uk/blog/caffeinate), or [amphetamine](https://apps.apple.com/us/app/amphetamine/id937984704?mt=12). \n",
    "supporting": [
      "simulation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}