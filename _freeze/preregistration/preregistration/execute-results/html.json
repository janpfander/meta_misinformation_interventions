{
  "hash": "cf29f08e5a5680b931be88b3b8f1fa60",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: |\n  Pre-data collection registration\nsubtitle: How effective are interventions designed to help people detect misinformation?\ntitle-block-banner: true\nexecute:\n  message: false\n  warning: false\n  \nabstract: |\n  \n  \n  In recent years, many studies have proposed individual-level interventions to reduce people's susceptibility for believing in misinformation. However, the results are often not directly comparable, because researchers have used different modes of evaluating the effectiveness of these interventions. Here, we will re-assess the findings of this literature in a Signal Detection Theory (SDT) framework. This allows us to differentiate between two different kinds of intervention effects: First, the effect on sensitivity, which is the ability of discriminating between true and false news that researchers typically look for. Second, the effect on response bias, which is the extent to which participants become generally more/less skeptical in their accuracy ratings for all news (whether true or false). We will run an Individual Participant Data (IPD) meta-analysis based on a sample of studies that we identified via a systematic literature review following the PRISMA guidelines. We will use a two-stage approach: First, we extract individual participant data and run a Signal Detection Theory analysis separately for each experiment. Second, we will run a meta-analysis on the experiment-level outcomes.\n  \nbibliography: ../references.bib\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# load plot theme\nsource(\"../R/plot_theme.R\") \n\n# load other functions\nsource(\"../R/custom_functions.R\")\n```\n:::\n\n\n\n\n\n\n::: {.callout-note}\nThis preregistration has been [registered on the OSF on December 2, 2024](https://osf.io/gkjuz).\n:::\n\n# Introduction\n\nIn recent years, many studies have tested interventions designed to help people detect online misinformation. However, the results are often not directly comparable, because researchers have used different modes of evaluating the effectiveness of these interventions [@guayHowThinkWhether2023]. Moreover, the most popular outcome measure--a discernment score based on Likert-scale mean differences between true and false news--has recently been shown to be biased [@highamMeanRatingDifference2024a].\n\nThe aim of this study re-analyze these studies in a common framework to draw new conclusions about the effectiveness of individual-level interventions designed to reduce people's susceptibility for believing in misinformation. Following a recent literature [@highamMeanRatingDifference2024a; @gawronskiSignaldetectionFrameworkMisinformation2024; @modirrousta-galianGamifiedInoculationInterventions2023; @bataillerSignalDetectionApproach2019] we will use a Signal Detection Theory (SDT) framework. This allows us to evaluate two different effects of interventions: First, the effect on sensitivity, which is the ability of discriminating between true and false news. Second, the effect on response bias, which is the extent to which participants shift their general response criterion, i.e. the extent to which they become generally more/less skeptical in their accuracy ratings for all news (regardless of whether true or false).\n\nWe formulate two main research questions: How do interventions against misinformation affect: (i) people's ability to discriminate between true and false news (sensitivity, or \"d'\", in a SDT framework; RQ1)?, and (ii) people's skepticism towards news in general (i.e. response bias, or \"c\", in a SDT framework; RQ2)?\n\nWe will also test some moderator effects. At this stage, we know that we will ask the following questions: Do the effects of the interventions (both on sensitivity and response bias) differ between (i) different types of interventions; (ii) politically concordant and politically discordant news; (iii) different age groups? It is likely that after data collection, we will have a better overview of variables and would want to ask more moderator questions. If that is the case, we will specify these moderators in a second pre-registration before analysis.\n\nWe will do an [Individual Participant Data meta-analysis (IPD)](https://training.cochrane.org/handbook/current/chapter-26), using a two-stage approach: First, we extract individual participant data from relevant studies and run a Signal Detection Theory analysis separately for each experiment. Second, we run a meta-analysis on the outcomes of the experiments.\n\n# Methods\n\n## Data/Sampling\n\n### Systematic Literature review\n\nWe will base ourselves on the systematic literature review of a recent meta-analysis on people's accuracy judgments of true and false news [@pfanderSpottingFalseNews2024]. Of all the studies extracted from this review, we will reduce our sample to those that tested an intervention to augment news discernment.\n\nSince the field is rapidly growing, we will also try to add papers that have been published since the systematic review. We will code for all papers whether they were part of the original systematic review of @pfanderSpottingFalseNews2024 or identified afterwards, so that the selection process is transparent. In a second pre-registration–after data collection but before analysis–we will publish a full list of studies, detailing whether they were part of the systematic review or added afterwards by us because we came across them.\n\nWe have already stored individual level data for several studies used in @pfanderSpottingFalseNews2024. We have yet to collect data for the remaining studies. For the studies for which we already have stored individual-level data, we have not yet cleaned it according to the requirements of the study proposed here. We have not performed any of the here suggested analysis on the collected data. We have simulated data to be clear on the data structure our analysis requires and to test how well our model performs in recovering parameters. All analyses presented in this pre-registration use this simulated data.\n\n### Selecting Interventions\n\nSometimes, within the same experiment, researchers test different interventions, by comparing it to a single control group. For a meta-analysis, this is a problem, [sometimes referred to as double-counting](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html#unit-of-analysis). Dependencies between effect sizes based on the same comparison group cannot be accounted for by a meta-analytic model [@harrer2021]. As a consequence, we will have to make a selection of for experiments that test several interventions at the same time: Following options recommended in the [cochrane manual](https://training.cochrane.org/handbook/current/chapter-23#section-23-3) we use the following rule of thumb: If the interventions are conceptually similar enough, pool the interventions together. If they are too dissimilar, pick the most pertinent one.\n\nIt is hard to predict in advance how relevant these decisions will be. However, we will make them on a purely theoretical basis: Once we have collected our data, we will make an overview of all interventions, and make a decision in case of multiple intervention arms within the same experiment. We will preregister these decisions as part of the second pre-registration. Only then will we run the analysis.\n\nWe have tried to mimic the situation of multiple intervention groups but only one control group in our simulated data. Some experiments have several interventions, and they are sometimes conceptually similar, sometimes different. @tbl-intervention-selection-a shows the experimental structure of the first two simulated papers.\n\n\n\n\n::: {#tbl-intervention-selection-a .cell}\n\n```{.r .cell-code}\ndata %>% \n  filter(paper_id %in% c(1:2)) %>% \n  distinct(paper_id, experiment_id, intervention_id, intervention_type) %>% \n  kable(caption = \"Experimental structure of the first two simulated papers\",\n        booktabs = TRUE) %>% \n    kable_styling(font_size = 10) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 10px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Experimental structure of the first two simulated papers</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> paper_id </th>\n   <th style=\"text-align:right;\"> experiment_id </th>\n   <th style=\"text-align:right;\"> intervention_id </th>\n   <th style=\"text-align:left;\"> intervention_type </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:left;\"> control </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> priming </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:left;\"> control </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> warning labels </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:left;\"> control </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> priming </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> warning labels </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:left;\"> control </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> warning labels </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nIn Paper 1, there are two experiments (experiment_id = '1' and experiment_id = '2'). Both experiments only have two arms, respectively: the control group and an intervention group (priming for Experiment 1; warning labels for Experiment 2). In these cases, since there is only one intervention, there is no decision to make as to which intervention to keep. By contrast, the first experiment of Paper 2 has three arms, among with two different intervention types ('priming' and 'warning labels'). In such a case, we would need to make a decision on which intervention type to keep. This decision will probably depend on which intervention type occurred how many times etc.\n\nIn our data, we will first detect all experiments with multiple interventions (@tbl-intervention-selection-b).\n\n\n\n\n::: {#tbl-intervention-selection-b .cell}\n\n```{.r .cell-code}\nconflict <- data %>% \n  distinct(paper_id, experiment_id, unique_experiment_id, intervention_id, intervention_type) %>% \n  group_by(unique_experiment_id) %>% \n  # substact 1 because of the control condition\n  summarize(n_different_intervention_types = n_distinct(intervention_type) - 1, \n            # display different intervention types\n            types = paste(unique(intervention_type), collapse = \", \")\n            ) %>% \n  # label all experiments with more than one intervention type\n  mutate(conflict = ifelse(n_different_intervention_types > 1, TRUE, FALSE)) %>% \n  filter(conflict == TRUE)\n\nconflict %>% \n  kable(caption = \"Studies with mutliple intervention arms in the simulated data\", \n        booktabs = TRUE) %>% \n    kable_styling(font_size = 10) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 10px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Studies with mutliple intervention arms in the simulated data</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> unique_experiment_id </th>\n   <th style=\"text-align:right;\"> n_different_intervention_types </th>\n   <th style=\"text-align:left;\"> types </th>\n   <th style=\"text-align:left;\"> conflict </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 10_2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, priming, literacy tips </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 10_3 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, priming, warning labels </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2_1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, priming, warning labels </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3_1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, warning labels, literacy tips </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4_1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, literacy tips, priming </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5_1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, warning labels, priming </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6_1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, literacy tips, priming </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6_2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, warning labels, literacy tips </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 7_1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, literacy tips, priming </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 7_3 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, priming, literacy tips </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 8_1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, warning labels, priming </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 9_1 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, warning labels, priming </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 9_2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> control, literacy tips, priming </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nWe will then have to make specific exclusion decisions for each experiment (@tbl-exclusion-decisions).\n\n\n\n\n::: {#tbl-exclusion-decisions .cell}\n\n```{.r .cell-code}\nconflict <- conflict %>% \n  # list all intervention types to be excluded for a given experiment\n  mutate(exclude =   case_when(unique_experiment_id == \"1_1\" ~ \"priming, warning labels\",\n                               unique_experiment_id == \"10_1\" ~ \"priming\",\n                               unique_experiment_id == \"10_3\" ~ \"warning labels\",\n                               # continue this list for all studies (we don't do this here because lazy)\n                               TRUE ~ NA_character_\n  )\n  ) %>% \n  select(unique_experiment_id, exclude)\n\nconflict %>% \n  kable(caption = \"Example of exclusion decisions for some of the experiments with multiple intervention arms\", \n        booktabs = TRUE) %>% \n    kable_styling(font_size = 10) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 10px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Example of exclusion decisions for some of the experiments with multiple intervention arms</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> unique_experiment_id </th>\n   <th style=\"text-align:left;\"> exclude </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 10_2 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 10_3 </td>\n   <td style=\"text-align:left;\"> warning labels </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2_1 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3_1 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4_1 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5_1 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6_1 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6_2 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 7_1 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 7_3 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 8_1 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 9_1 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 9_2 </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nWe then filter our data to only keep the intervention conditions we decided upon (@tbl-exclusion-filter).\n\n\n\n\n::: {#tbl-exclusion-filter .cell}\n\n```{.r .cell-code}\ndata <- data %>% \n  left_join(conflict) %>% \n  # Use str_detect to check if intervention_type is found in exclude string\n  filter(is.na(exclude) | !str_detect(exclude, intervention_type))\n\n# check\n# data %>%\n#   distinct(paper_id, experiment_id, unique_experiment_id, intervention_id, intervention_type, condition) %>%\n#   filter(unique_experiment_id %in% c(\"10_1\", \"2_1\", \"5_1\"))\n```\n:::\n\n\n\n\nOnce all decisions regarding the intervention selections have been made, we can rely our 'condition' variable for all models below, which takes only the values of either 'control' or 'intervention'.\n\n## Analysis plan\n\n### Outcomes\n\nWe want to measure the effects of misinformation interventions on two outcomes of Signal Detection Theory (SDT): $d'$ (\"d prime\", sensitivity), and $c$ (response bias). @tbl-sdt-vocabulary shows how instances of news ratings map onto SDT terminology.\n\n\n\n\n::: {#tbl-sdt-vocabulary .cell}\n\n```{.r .cell-code}\n# Data\ntable_data <- tibble(\n  Stimulus = c(\"True news (target)\",\"False news (distractor)\"),\n  Accurate = c(\"Hit\", \"False alarm\"),\n  `Not Accurate` = c(\"Miss\", \"Correct rejection\")\n)\n\n# Set Stimulus as row names\n# rownames(table_data) <- table_data$Stimulus\n# table_data$Stimulus <- NULL\n\n# Create table using kable\nkable(table_data, \n      caption = \"Accuracy ratings in Signal Detection Theory terms\", \n              booktabs = TRUE) %>%\n  kable_paper(full_width = FALSE) %>%\n  add_header_above(c(\" \", \"Response\" = 2))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-paper\" style='font-family: \"Arial Narrow\", arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;'>\n<caption>Accuracy ratings in Signal Detection Theory terms</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;\" colspan=\"1\"></th>\n<th style=\"padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #00000020; padding-bottom: 5px; \">Response</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Stimulus </th>\n   <th style=\"text-align:left;\"> Accurate </th>\n   <th style=\"text-align:left;\"> Not Accurate </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> True news (target) </td>\n   <td style=\"text-align:left;\"> Hit </td>\n   <td style=\"text-align:left;\"> Miss </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> False news (distractor) </td>\n   <td style=\"text-align:left;\"> False alarm </td>\n   <td style=\"text-align:left;\"> Correct rejection </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# make SDT variables\nsdt_data <- data %>% \n  # code ratings in terms of SDT language\n  mutate(sdt_outcome = case_when(accuracy == 1 & veracity == \"true\" ~ \"hit\", \n                                 accuracy == 1 & veracity == \"fake\" ~ \"false_alarm\",\n                                 accuracy == 0 & veracity == \"true\" ~ \"miss\",\n                                 accuracy == 0 & veracity == \"fake\" ~ \"correct_rejection\",\n                                 .default =  NA)\n         )\n```\n:::\n\n\n\n\nThe sensitivity, $d’$, measures people's capacity to discriminate between true and false news. It is defined as the difference of the standardized hit and false alarm rates\n\n$$\nd' = \\Phi^{-1}(HR) - \\Phi^{-1}(FAR) \n$$\n\nwhere $HR$ refers to hit rate or the proportion of true news trials that participants classified--correctly--as \"accurate\" ($HR = \\frac{N_{Hits}}{N_{Hits} + N_{Misses}}$), $FAR$ refers to false alarm rate or the proportion of false news trials that participants classified--incorrectly--as \"accurate\" ($HR = \\frac{N_{False Alarms}}{N_{FalseAlarms} + N_{Correct Rejections}}$). $\\Phi$ is the cumulative normal density function, and is used to convert z scores into probabilities. Its inverse, $\\Phi^{-1}$, converts a proportion (such as a hit rate or false alarm rate) into a z score. Below, we refer to standardized hit and false alarm rates as zHR and zFAR, respectively. Due to this transformation, a proportion of .5 is converted to a z score of 0 (reflecting responses at chance). Proportions greater than .5 produce positive z scores, and proportions smaller than .5 negative ones. A positive $d'$ score indicates that people rate true news as more accurate than false news.\n\nThe response bias, $c$ can be conceived of as an overall tendency to rate items as accurate. It is defined as\n\n$$\nc = -\\frac{1}{2}(\\text{zHR} + \\text{zFAR})\n$$\n\nNote that $c$ = 0 when $zFAR = -zHR$. Because $-zHR = z(1-HR)$ is the (z-transformed) share of misses (true news rated as \"not accurate\"), $c$ = 0 when the false alarm rate is equal to the rate of misses (Macmillan & Creelman (2004). In other words, if people--mistakenly--rate true news as not accurate (the rate of misses) as much as they--mistakenly--rate false false news as accurate (the rate of false alarms), then there is no response bias. A positive $c$ score occurs when the miss rate (rating true news news as false) is larger than the false alarm rate (rating false news as true). In other words, a positive $c$ score indicates that people were more skeptical towards true news than they were gullible towards false news. We refer to this as an overall tendency towards skepticism.\n\nOur outcomes of interest are the intervention effects on $d'$ (\"d prime\", sensitivity) and $c$ (response bias). Since these outcomes are about the difference between the control and the treatment group, we call them \"Delta\". Specifically, they are defined as:\n\n$$\n\\Delta d' = d'_{treatment} - d'_{control}\n$$\n\nand\n\n$$\n\\Delta c = c_{treatment} - c_{control}.\n$$\n\nA positive $\\Delta d'$ score indicates that the intervention increased participants' ability to discriminate between true and false news compared to the control group. A positive $\\Delta c$ score indicates that the intervention led to a greater tendency towards skepticism, meaning participants were more likely to rate items as \"not accurate\" regardless of veracity, compared to the control group.\n\n### Variables\n\n@tbl-codebook contains a list of variables we will collect. We might not be able to collect all variables for all studies. For political concordance, e.g., this will certainly not be the case.\n\n\n\n\n::: {#tbl-codebook .cell}\n\n```{.r .cell-code}\n# Create the codebook data frame\ncodebook <- data.frame(\n  Variable_Name = c(\n    \"paper_id\", \"experiment_id\", \"subject_id\", \"country\", \"year\", \n    \"veracity\", \"condition\", \"intervention_label\", \"intervention_description\", \n    \"intervention_selection\",\n    \"accuracy_raw\", \"scale\", \"originally_identified_treatment_effect\", \n    \"concordance\", \"age\", \"age_range\", \"identified_via\", \"id\", \n    \"unique_experiment_id\", \"accuracy\"\n  ),\n  Description = c(\n    \"Identifier for each paper\",\n    \"Identifier for each experiment within a paper\",\n    \"Identifier of individual participants within an experiment\",\n    \"The country of the sample\",\n    \"Ideally year of data collection, otherwise year of publication\",\n    \"Identifying false and true news items\",\n    \"Treatment vs. control\",\n    \"A label for what the intervention consisted of\",\n    \"A detailed description of the intervention\",\n    \"If multiple interventions tested within a single experiment (and related to a single control group), reasoning as to which intervention to select\",\n    \"Participants' accuracy ratings on the scale used in the original study\",\n    \"The scale used in the original study\",\n    \"Whether the authors identified a significant treatment effect (`FALSE` if no, `TRUE` if yes)\",\n    \"Political concordance of news items (concordant or discordant)\",\n    \"Participant age. In some cases, participant age will not be exact, but within a binned category. In this case, we will take the mid-point of this category for the age variable\",\n    \"Binned age, if only this is provided by the study.\",\n    \"Indicates if a paper was identified by the systematic review or added after\",\n    \"Unique participant ID (merged `paper_id`, `experiment_id`, `subject_id`)\",\n    \"Unique experiment ID (merged `paper_id` and `experiment_id`)\",\n    \"Binary version of `accuracy_raw`; unchanged if originally binary\"\n  )\n)\n\n# Generate the styled table with kableExtra\nkable(codebook, \n      caption = \"Codebook for variables to collect\",\n      col.names = c(\"Variable Name\", \"Description\"),\n      booktabs = TRUE,\n      longtable = TRUE,) %>%\n  kable_styling(latex_options = \"repeat_header\",\n                font_size = 10) %>% \n  column_spec(1, bold = TRUE) %>%  # Bold the first column\n  column_spec(2, width = \"25em\") %>%  # Set width for the description column\n  row_spec(0, bold = TRUE)  # Bold the header row\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 10px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Codebook for variables to collect</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;font-weight: bold;\"> Variable Name </th>\n   <th style=\"text-align:left;font-weight: bold;\"> Description </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> paper_id </td>\n   <td style=\"text-align:left;width: 25em; \"> Identifier for each paper </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> experiment_id </td>\n   <td style=\"text-align:left;width: 25em; \"> Identifier for each experiment within a paper </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> subject_id </td>\n   <td style=\"text-align:left;width: 25em; \"> Identifier of individual participants within an experiment </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> country </td>\n   <td style=\"text-align:left;width: 25em; \"> The country of the sample </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> year </td>\n   <td style=\"text-align:left;width: 25em; \"> Ideally year of data collection, otherwise year of publication </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> veracity </td>\n   <td style=\"text-align:left;width: 25em; \"> Identifying false and true news items </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> condition </td>\n   <td style=\"text-align:left;width: 25em; \"> Treatment vs. control </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> intervention_label </td>\n   <td style=\"text-align:left;width: 25em; \"> A label for what the intervention consisted of </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> intervention_description </td>\n   <td style=\"text-align:left;width: 25em; \"> A detailed description of the intervention </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> intervention_selection </td>\n   <td style=\"text-align:left;width: 25em; \"> If multiple interventions tested within a single experiment (and related to a single control group), reasoning as to which intervention to select </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> accuracy_raw </td>\n   <td style=\"text-align:left;width: 25em; \"> Participants' accuracy ratings on the scale used in the original study </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> scale </td>\n   <td style=\"text-align:left;width: 25em; \"> The scale used in the original study </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> originally_identified_treatment_effect </td>\n   <td style=\"text-align:left;width: 25em; \"> Whether the authors identified a significant treatment effect (`FALSE` if no, `TRUE` if yes) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> concordance </td>\n   <td style=\"text-align:left;width: 25em; \"> Political concordance of news items (concordant or discordant) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> age </td>\n   <td style=\"text-align:left;width: 25em; \"> Participant age. In some cases, participant age will not be exact, but within a binned category. In this case, we will take the mid-point of this category for the age variable </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> age_range </td>\n   <td style=\"text-align:left;width: 25em; \"> Binned age, if only this is provided by the study. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> identified_via </td>\n   <td style=\"text-align:left;width: 25em; \"> Indicates if a paper was identified by the systematic review or added after </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> id </td>\n   <td style=\"text-align:left;width: 25em; \"> Unique participant ID (merged `paper_id`, `experiment_id`, `subject_id`) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> unique_experiment_id </td>\n   <td style=\"text-align:left;width: 25em; \"> Unique experiment ID (merged `paper_id` and `experiment_id`) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> accuracy </td>\n   <td style=\"text-align:left;width: 25em; \"> Binary version of `accuracy_raw`; unchanged if originally binary </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nBuilding a comparable accuracy measure that we can analyze in the SDT framework outlined here, requires collapsing scales. The studies that we will look at use a variety of scales. Some use a binary scale, which is the one that is the most straightforward to use in a SDT framework (signal vs. no signal) and thus also the one we have simulated. However, a lot of studies use Likert-type scales. For these studies, we will collapse the original scores into a dichotomized version with answers of either 'not accurate' (0) or 'accurate' (1). For example, a study might have used a 4-point scale going from 1, not accurate at all, to 4, completely accurate. In this case, we will code responses of 1 and 2 as not accurate (0) and 3 and 4 as accurate (1). For scales, with a mid-point (example 3 on a 5-point scale), we will code midpoint answers as 'NA', meaning they will be excluded from the analysis.\n\n### Main Analysis\n\nWe will run a participant-level meta analysis using a two-stage approach: First, for each experiment, we calculate a generalized linear mixed model (glmm) that yields SDT outcomes. The resulting estimates are our effect sizes. Second, we run a meta analysis on these effect sizes. In Appendix @sec-step-by-step to this registration, we explain step by step how to go from a by-hand SDT analysis to a glmm SDT analysis. In the following, we will outline the analysis steps we will perform.\n\n#### Stage 1: experiment-level analysis\n\nFor each experiment, we run a separate participant-level SDT analysis. Because participants provide several ratings, we use mixed-models with random participant effects that account for the resulting dependency in the data points. We use random effects both for the intercept and the effect of veracity. We do not use random effects for condition or the interaction of condition and veracity, as condition is typically manipulated between participants. We can obtain SDT outcomes directly from a generalized linear mixed model (glmm) when using a probit link function (see Appendix @sec-step-by-step). @tbl-example-outcome-exp1 shows the model output for our simulated Experiment 1, from paper 1.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate model function\ncalculate_model <- function(data) {\n  \n  time <- system.time({\n    model <- glmer(accuracy ~ veracity_numeric + condition_numeric + \n                     veracity_numeric*condition_numeric +\n                     (1 + veracity_numeric | unique_subject_id),\n                   data = data, \n                   family = binomial(link = \"probit\")\n    )\n  })\n  \n  time <- round(time[3]/60, digits = 2)\n  \n  # get a tidy version\n  model <- tidy(model, conf.int = TRUE) %>% \n    # add time\n    mutate(time_minutes = time)\n  \n  return(model)\n  \n}\n# test\n# mixed_model <- calculate_model(data %>% filter(unique_experiment_id == \"1_1\"))\n# mixed_model\n```\n:::\n\n\n\n\nWe calculate one model per experiment and store the results in a common data frame.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Running this model takes some time. We therefor stored the results in a data frame that we can reload. \nfilename <- \"../data/simulations/models_by_experiment.csv\" \n\nrun_loop <- function(data, filename){\n  \n  # only execute the following if the file does NOT exist\n  if (!file.exists(filename)) {\n    \n    # make a vector with all unique experiment ids\n    experiments <- data %>% \n      distinct(unique_experiment_id) %>% \n      # slice(1:3) %>% # to test loop\n      pull()\n    \n    time <- system.time({\n      \n      # run one model per experiment and store the results in a common data frame\n      results <- experiments %>%\n        map_dfr(function(x) {\n          \n          # restrict data to only the respective experiment\n          experiment <- data %>% filter(unique_experiment_id == x)\n          \n          # extract paper id\n          paper_id <- unique(experiment$paper_id)\n          \n          # To keep track of progress\n          print(paste(\"calculating model for experiment \", x))\n          \n          model_experiment <- calculate_model(experiment) %>%\n            mutate(unique_experiment_id = x,\n                   paper_id = paper_id)\n          \n          return(model_experiment)\n        })\n    })\n    \n    write_csv(results, filename)\n    \n    print(paste(\"Elapsed time: \", round(time[3]/60, digits = 2), \" minutes\"))\n  }\n  \n}\n\n# execute function\nrun_loop(data, filename)\n\n# read saved model results\nmodel_results <- read_csv(filename)\n```\n:::\n\n\n\n\nWe code our binary independent variables, veracity and condition, using deviation coding (i.e. for veracity, false = -0.5, true = 0.5; for condition, control = -0.5, treatment = 0.5). Using deviation coding, the main effect model output terms translate to SDT outcomes as follows:\n\n-   `(Intercept)` = average -$c$, pooled across all conditions\n-   `veracity_numeric` = average $d'$, pooled across all conditions\n-   `condition_numeric` = -$\\Delta c$, i.e. the change in -response bias between control and treatment\n-   `veracity_numeric:condition_numeric` = $\\Delta d'$, i.e. the change in sensitivity between control and treatment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# We clean up the model output by naming our estimates of interest in terms of SDT outcomes, and reversing the coefficients for response bias c, and delta response bias c.\n\nmodel_results <- model_results %>% \n  filter(effect == \"fixed\") %>% \n  mutate(\n    # make sdt outcomes\n    SDT_term = case_when(\n    term == \"(Intercept)\" ~ \"average c\",\n    term == \"veracity_numeric\" ~ \"average d'\",\n    term == \"condition_numeric\" ~ \"delta c\",\n    term == \"veracity_numeric:condition_numeric\" ~ \"delta d'\",\n    TRUE ~ \"Other\"\n  ), \n  # reverse c and delta c estimates\n  SDT_estimate = ifelse(term == \"(Intercept)\" | term == \"condition_numeric\", \n                        -1*estimate, estimate),\n    sampling_variance = std.error^2\n  ) \n```\n:::\n\n::: {#tbl-example-outcome-exp1 .cell}\n\n```{.r .cell-code}\nmodel_results %>% \n  filter(unique_experiment_id == \"1_1\") %>% \n  select(-starts_with(\"conf\")) %>% \n  rounded_numbers() %>% \n  select(-c(effect, group)) %>% \n  kable(\n    caption = \"Results of a generalize linear mixed model (glmm)\",\n    booktabs = TRUE) %>%\n  kable_styling(font_size = 8,  # Set a smaller font size\n                latex_options = c(\"scale_down\")) # Scale down the table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 8px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Results of a generalize linear mixed model (glmm)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> time_minutes </th>\n   <th style=\"text-align:left;\"> unique_experiment_id </th>\n   <th style=\"text-align:right;\"> paper_id </th>\n   <th style=\"text-align:left;\"> SDT_term </th>\n   <th style=\"text-align:right;\"> SDT_estimate </th>\n   <th style=\"text-align:right;\"> sampling_variance </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -0.514 </td>\n   <td style=\"text-align:right;\"> 0.032 </td>\n   <td style=\"text-align:right;\"> -16.175 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:left;\"> 1_1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> average c </td>\n   <td style=\"text-align:right;\"> 0.514 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric </td>\n   <td style=\"text-align:right;\"> 0.786 </td>\n   <td style=\"text-align:right;\"> 0.062 </td>\n   <td style=\"text-align:right;\"> 12.711 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:left;\"> 1_1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> average d' </td>\n   <td style=\"text-align:right;\"> 0.786 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.119 </td>\n   <td style=\"text-align:right;\"> 0.063 </td>\n   <td style=\"text-align:right;\"> -1.892 </td>\n   <td style=\"text-align:right;\"> 0.059 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:left;\"> 1_1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> delta c </td>\n   <td style=\"text-align:right;\"> 0.119 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.285 </td>\n   <td style=\"text-align:right;\"> 0.123 </td>\n   <td style=\"text-align:right;\"> -2.312 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:left;\"> 1_1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> delta d' </td>\n   <td style=\"text-align:right;\"> -0.285 </td>\n   <td style=\"text-align:right;\"> 0.015 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nAs shown in @fig-distributions, we can then plot the distributions of our outcome estimates of interest, across experiments.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make plot\nggplot(model_results, aes(x = estimate, fill = SDT_term)) +\n  geom_density(alpha = 0.5, adjust = 1.5) +\n  # colors \n  scale_fill_viridis_d(option = \"inferno\", begin = 0.1, end = 0.9) +\n  # labels and scales\n  labs(x = \"z-Score\", y = \"Density\") +\n  guides(fill = FALSE, color = FALSE) +\n  plot_theme +\n  theme(strip.text = element_text(size = 14)) +\n  facet_wrap(~SDT_term)\n```\n\n::: {.cell-output-display}\n![Distributions of Signal Detection Theory outcomes across experiments. Note that these distributions are purely descriptive - effect sizes are not weighted by sample size of the respective experiment, as they are in the meta-analysis.](preregistration_files/figure-html/fig-distributions-1.png){#fig-distributions width=672}\n:::\n:::\n\n\n\n\n#### Stage 2: Meta-analysis\n\nNext, we run a meta analysis on these effect size estimates at the experiment-level. In our models for the meta analysis, each effect size is weighted by the inverse of its standard error, thereby giving more weight to experiments with larger sample sizes. We will use random effects models, which assume that there is not only one true effect size but a distribution of true effect sizes. We will use a multi-level meta-analytic model, with random effects at the publication and the experiment level. This approach allows us to account for the hierarchical structure of our data, in which (at least some) papers (level three) contribute several effect sizes from different experiments (level two)[^1]. However, the multi-level models do not account for dependencies in sampling error. When one paper contributes several effect sizes, one might expect their respective sampling errors to be correlated. To account for dependency in sampling errors, we compute cluster-robust standard errors, confidence intervals, and statistical tests for all meta-analytic estimates. For our simulated data, @tbl-meta-model-results shows the results of the meta-analytic models and @fig-forest provides an overview of effect sizes for each experiment as a forest plot.\n\n[^1]: Level 1 being the the participant level, i.e. the sampling variation of the original studies, see @harrer2021.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate meta models\ncalculate_models <- function(data, yi, vi, robust = TRUE) {\n  \n  # provide metafor compatible names\n  metafor_data <- data %>% \n    rename(yi = {{yi}}, \n           vi = {{vi}})\n  \n  # Multilevel random effect model for accuracy\n  model <-  metafor::rma.mv(yi, vi, random = ~ 1 | paper_id / unique_experiment_id, \n                            data = metafor_data)\n  \n  return(model)\n  \n  if(robust == TRUE) {\n    # with robust standard errors clustered at the paper level \n    robust_model <- robust(model, cluster = data$paper_id)\n    \n    return(robust_model)\n  }\n}\n```\n:::\n\n::: {#tbl-meta-model-results .cell}\n\n```{.r .cell-code}\n# model for delta dprime\ndelta_dprime <- calculate_models(data = model_results %>% \n                                   filter(SDT_term == \"delta d'\"), yi = SDT_estimate, \n                                 vi = sampling_variance, robust = TRUE)\n\n# model for delta c\ndelta_c <- calculate_models(data = model_results %>% \n                                   filter(SDT_term == \"delta c\"), yi = SDT_estimate, \n                                 vi = sampling_variance, robust = TRUE)\n\n\nmodelsummary::modelsummary(list(\"Delta d'\" = delta_dprime, \n                                \"Delta c\" = delta_c\n                                ), \n                           title = \"Results of Meta-analysis\",\n                           stars = TRUE, \n                           output = \"kableExtra\"\n                           )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n<caption>Results of Meta-analysis</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Delta d' </th>\n   <th style=\"text-align:center;\"> Delta c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> overall </td>\n   <td style=\"text-align:center;\"> 0.100* </td>\n   <td style=\"text-align:center;\"> 0.078* </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.043) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.032) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 21 </td>\n   <td style=\"text-align:center;\"> 21 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> −8.1 </td>\n   <td style=\"text-align:center;\"> −20.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> −4.9 </td>\n   <td style=\"text-align:center;\"> −17.3 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up a 1x2 layout for the two plots\npar(mfrow = c(1, 2))\n\n# Calculate weights (e.g., inverse of standard error)\nmodel_results <- model_results %>%\n  mutate(weight = 1 / sqrt(sampling_variance))\n\n# Create plot for d'\nforest.rma(delta_dprime,\n           xlim = c(-1, 2),          # Adjust horizontal plot region limits\n           at = c(-1, -0.5, 0, 1, 2), \n           order = \"obs\",            # Order by size of yi\n           slab = unique_experiment_id, \n           annotate = TRUE,          # Study labels and annotations\n           efac = c(0, 1),           # Remove vertical bars at end of CIs\n           pch = 15,                 # Change point symbol to filled squares\n           col = \"gray40\",           # Change color of points/CIs\n           cex.lab = 0.8, \n           cex.axis = 0.8,           # Increase size of x-axis title/labels\n           lty = c(\"solid\", \"dotted\", \"blank\"),  # Remove horizontal line at top of plot\n           mlab = \"BLASt\", \n           ylim = c(-2, n_distinct(model_results$unique_experiment_id)), \n           addfit = FALSE, \n           xlab = \"Delta d'\") \naddpoly(delta_dprime, mlab = \" \", cex = 1, row = -2) \nabline(h = 0)\n\n# Create plot for c\nforest.rma(delta_c,\n           xlim = c(-1, 2),          # Adjust horizontal plot region limits\n           at = c(-1, -0.5, 0, 1, 2), \n           order = \"obs\",            # Order by size of yi\n           slab = unique_experiment_id, \n           annotate = TRUE,          # Study labels and annotations\n           efac = c(0, 1),           # Remove vertical bars at end of CIs\n           pch = 15,                 # Change point symbol to filled squares\n           col = \"gray40\",           # Change color of points/CIs\n           cex.lab = 0.8, \n           cex.axis = 0.8,           # Increase size of x-axis title/labels\n           lty = c(\"solid\", \"dotted\", \"blank\"),  # Remove horizontal line at top of plot\n           mlab = \"BLASt\", \n           ylim = c(-2, n_distinct(model_results$unique_experiment_id)), \n           addfit = FALSE, \n           xlab = \"Delta c\") \naddpoly(delta_c, mlab = \" \", cex = 1, row = -2) \nabline(h = 0)\n\n# Reset the layout to the default (1x1)\npar(mfrow = c(1, 1))\n```\n\n::: {.cell-output-display}\n![*Forest plots for delta d' and delta c*. The figure displays all effect sizes for both outcomes. Effects are weighed by their sample size. Effect sizes are z-values. Horizontal bars represent 95% confidence intervals. The average estimate is the result of a multilevel meta model with clustered standard errors at the sample level.](preregistration_files/figure-html/fig-forest-1.png){#fig-forest width=672}\n:::\n:::\n\n\n\n\n### Moderator analysis\n\nWe distinguish between two broad kinds of moderator variables: those that vary within-experiments (e.g. political concordance) and those that vary between experiments (e.g. intervention type). We will use different approaches for these two kinds.\n\n#### a. within-experiment variables\n\nThere are two moderator variables that vary within-experiments that we will test: age and political concordance. Age varies within experiments, but between participants (each participant can only have one age). Political concordance varies not only within experiments, and also within participants--in the typical experiment design, each participant is shown both concordant and discordant items. In the follwing, we will focus on political concordance, which requires slightly more complex modelling, but provide the models for age in the respective code chunks^[visible only in the .html version].\n\nWe have two options: The first is integrating political concordance in our baseline model. While this would be the straightforward thing to do, it involves a three-way interaction with many random effects and will likely bring up convergence issues. The second option is to run our baseline model separately for concordant and discordant items, and then proceed as for between-experiment moderators. We will try the first option first, and only revert to the second if we encounter serious convergence issues. \n\n##### i. Integrating Concordance in baseline model\n\nIn the first option, we add political concordance to our Stage 1 model, such that we have a three-way interaction between veracity, condition and political concordance.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate model function for political concordance\ncalculate_concordance_model <- function(data) {\n  \n  time <- system.time({\n    model <- glmer(accuracy ~ veracity_numeric + condition_numeric + concordance_numeric + \n                     veracity_numeric*condition_numeric*concordance_numeric +\n                     (1 + veracity_numeric + veracity_numeric:concordance_numeric | \n                        unique_subject_id),\n                   data = data, \n                   family = binomial(link = \"probit\")\n    )\n  })\n  \n  time <- round(time[3]/60, digits = 2)\n  \n  # get a tidy version\n  model <- tidy(model, conf.int = TRUE) %>% \n    # add time\n    mutate(time_minutes = time)\n  \n  return(model)\n  \n}\n\n# calculate model function for age\ncalculate_age_model <- function(data) {\n  \n  time <- system.time({\n    model <- glmer(accuracy ~ veracity_numeric + condition_numeric + age + \n                     veracity_numeric*condition_numeric*age +\n                     (1 + veracity_numeric  | \n                        unique_subject_id),\n                   data = data, \n                   family = binomial(link = \"probit\")\n    )\n  })\n  \n  time <- round(time[3]/60, digits = 2)\n  \n  # get a tidy version\n  model <- tidy(model, conf.int = TRUE) %>% \n    # add time\n    mutate(time_minutes = time)\n  \n  return(model)\n  \n}\n# age_model <- calculate_age_model(data %>% filter(unique_experiment_id == \"1_1\"))\n# age_model %>% print(n = 14)\n```\n:::\n\n\n\n\n@tbl-glmm-example-experiment1 illustrates the model output for the first experiment (Experiment 1 of Paper 1) in our simulated data.\n\n\n\n\n::: {#tbl-glmm-example-experiment1 .cell}\n\n```{.r .cell-code}\nconcordance_model <- calculate_concordance_model(data %>% filter(unique_experiment_id == \"1_1\"))\nconcordance_model %>% \n  rounded_numbers() %>% \n  select(-c(effect, group)) %>% \n  kable(booktabs = TRUE, \n        caption = \"Results of the generalized linear mixed model (glmm) on the first experiment (Experiment 1 of Paper 1) in our simulated data.\") %>%\n  kable_styling(font_size = 8,  # Set a smaller font size\n                latex_options = c(\"scale_down\")) # Scale down the table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 8px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Results of the generalized linear mixed model (glmm) on the first experiment (Experiment 1 of Paper 1) in our simulated data.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n   <th style=\"text-align:right;\"> time_minutes </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -0.510 </td>\n   <td style=\"text-align:right;\"> 0.033 </td>\n   <td style=\"text-align:right;\"> -15.511 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -0.574 </td>\n   <td style=\"text-align:right;\"> -0.445 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric </td>\n   <td style=\"text-align:right;\"> 0.808 </td>\n   <td style=\"text-align:right;\"> 0.063 </td>\n   <td style=\"text-align:right;\"> 12.740 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.684 </td>\n   <td style=\"text-align:right;\"> 0.933 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.112 </td>\n   <td style=\"text-align:right;\"> 0.065 </td>\n   <td style=\"text-align:right;\"> -1.723 </td>\n   <td style=\"text-align:right;\"> 0.085 </td>\n   <td style=\"text-align:right;\"> -0.239 </td>\n   <td style=\"text-align:right;\"> 0.015 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> concordance_numeric </td>\n   <td style=\"text-align:right;\"> -0.095 </td>\n   <td style=\"text-align:right;\"> 0.063 </td>\n   <td style=\"text-align:right;\"> -1.504 </td>\n   <td style=\"text-align:right;\"> 0.133 </td>\n   <td style=\"text-align:right;\"> -0.219 </td>\n   <td style=\"text-align:right;\"> 0.029 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.287 </td>\n   <td style=\"text-align:right;\"> 0.126 </td>\n   <td style=\"text-align:right;\"> -2.283 </td>\n   <td style=\"text-align:right;\"> 0.022 </td>\n   <td style=\"text-align:right;\"> -0.534 </td>\n   <td style=\"text-align:right;\"> -0.041 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> -0.181 </td>\n   <td style=\"text-align:right;\"> 0.129 </td>\n   <td style=\"text-align:right;\"> -1.400 </td>\n   <td style=\"text-align:right;\"> 0.161 </td>\n   <td style=\"text-align:right;\"> -0.435 </td>\n   <td style=\"text-align:right;\"> 0.072 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> condition_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> -0.009 </td>\n   <td style=\"text-align:right;\"> 0.125 </td>\n   <td style=\"text-align:right;\"> -0.074 </td>\n   <td style=\"text-align:right;\"> 0.941 </td>\n   <td style=\"text-align:right;\"> -0.255 </td>\n   <td style=\"text-align:right;\"> 0.236 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:condition_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> -0.197 </td>\n   <td style=\"text-align:right;\"> 0.255 </td>\n   <td style=\"text-align:right;\"> -0.770 </td>\n   <td style=\"text-align:right;\"> 0.441 </td>\n   <td style=\"text-align:right;\"> -0.697 </td>\n   <td style=\"text-align:right;\"> 0.304 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sd__(Intercept) </td>\n   <td style=\"text-align:right;\"> 0.119 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> cor__(Intercept).veracity_numeric </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> cor__(Intercept).veracity_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sd__veracity_numeric </td>\n   <td style=\"text-align:right;\"> 0.085 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> cor__veracity_numeric.veracity_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sd__veracity_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> 0.342 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nGiven that all our binary variables in the data are deviation-coded (-0.5 vs. 0.5) outputs are to be interpreted as follows:\n\n-   `(Intercept)` = average -$c$, pooled across all conditions\n-   `veracity_numeric` = average $d'$, pooled across all conditions\n-   `condition_numeric` = -$\\Delta c_{\\text{condition}}$, i.e. the change in -response bias between control and treatment, pooled across concordant and discordant items\n-   `concordance_numeric` = -$\\Delta c_{\\text{concordance}}$, i.e. the change in -response bias between concordant and discordant items, pooled across control and treatment\n-   `veracity_numeric:condition_numeric` = $\\Delta d'_{\\text{condition}}$, i.e. the change in sensitivity between control and treatment, pooled across concordant and discordant items\n-   `veracity_numeric:concordance_numeric` = $\\Delta d'_{\\text{concordance}}$, i.e. the change in sensitivity between concordant and discordant items, pooled across control and treatment\n-   `condition_numeric:concordance_numeric` = Effect of concordance on -$\\Delta c_{\\text{condition}}$,\n-   `veracity_numeric:condition_numeric:concordance_numeric` = Effect of concordance on $\\Delta d'_{\\text{condition}}$\n\nSince interpretation can get a bit complex in three-way interactions [here is a good ressource](https://psyteachr.github.io/stat-models-v1/interactions.html#the-key-coding-schemes), we demonstrate below that the model estimates correspond to their respective SDT outcomes.\n\nTo do so, we first run the same model as before, on the same data as before (Experiment 1 of Paper 1), but removing the random effects, so that our model estimates will correspond to the estimates from a by-hand Signal Detection Theory analysis (@tbl-glm-example-experiment1).\n\n\n\n\n::: {#tbl-glm-example-experiment1 .cell}\n\n```{.r .cell-code}\n# same model as above, but without random effects \nglm_model <- glm(accuracy ~ veracity_numeric + condition_numeric + concordance_numeric + \n                     veracity_numeric*condition_numeric*concordance_numeric,\n                   data = data %>% filter(unique_experiment_id == \"1_1\"), \n                   family = binomial(link = \"probit\"))\n\n# give nicer names to estimates\nglm_model <- glm_model %>% \n  tidy() %>% \n  mutate(\n    # reverse c and delta c estimates\n    SDT_estimate = ifelse(term == \"(Intercept)\" | term == \"condition_numeric\" | term == \"concordance_numeric\" | term == \"condition_numeric:concordance_numeric\" , \n                      -1*estimate, estimate),\n    SDT_term = case_when(term == \"(Intercept)\" ~ \"average response bias (c)\", \n                     term == \"veracity_numeric\" ~ \"average sensitivity (d')\", \n                     term == \"condition_numeric\" ~ \"delta c (condition)\",\n                     term == \"concordance_numeric\" ~ \"delta c (concordance)\",\n                     term == \"veracity_numeric:condition_numeric\" ~ \"delta d' (condition)\",\n                     term == \"veracity_numeric:concordance_numeric\" ~ \"delta d' (concordance)\",\n                     term == \"condition_numeric:concordance_numeric\" ~ \"effect of concordance on delta c (condition)\",\n                     term == \"veracity_numeric:condition_numeric:concordance_numeric\" ~ \"effect of concordance on delta d' (condition)\",\n    )\n  ) \n\n\nglm_model %>% \n  rounded_numbers() %>% \n  kable(booktabs = TRUE, \n        caption = \"Results of the generalized linear model (glm), i.e. without random effects, on the first experiment (Experiment 1 of Paper 1) in our simulated data.\") %>%\n  kable_styling(font_size = 8,  # Set a smaller font size\n                latex_options = c(\"scale_down\")) # Scale down the table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 8px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Results of the generalized linear model (glm), i.e. without random effects, on the first experiment (Experiment 1 of Paper 1) in our simulated data.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> SDT_estimate </th>\n   <th style=\"text-align:left;\"> SDT_term </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -0.504 </td>\n   <td style=\"text-align:right;\"> 0.031 </td>\n   <td style=\"text-align:right;\"> -16.190 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.504 </td>\n   <td style=\"text-align:left;\"> average response bias (c) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric </td>\n   <td style=\"text-align:right;\"> 0.804 </td>\n   <td style=\"text-align:right;\"> 0.062 </td>\n   <td style=\"text-align:right;\"> 12.917 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.804 </td>\n   <td style=\"text-align:left;\"> average sensitivity (d') </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.109 </td>\n   <td style=\"text-align:right;\"> 0.062 </td>\n   <td style=\"text-align:right;\"> -1.750 </td>\n   <td style=\"text-align:right;\"> 0.080 </td>\n   <td style=\"text-align:right;\"> 0.109 </td>\n   <td style=\"text-align:left;\"> delta c (condition) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> concordance_numeric </td>\n   <td style=\"text-align:right;\"> -0.099 </td>\n   <td style=\"text-align:right;\"> 0.062 </td>\n   <td style=\"text-align:right;\"> -1.591 </td>\n   <td style=\"text-align:right;\"> 0.112 </td>\n   <td style=\"text-align:right;\"> 0.099 </td>\n   <td style=\"text-align:left;\"> delta c (concordance) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.282 </td>\n   <td style=\"text-align:right;\"> 0.125 </td>\n   <td style=\"text-align:right;\"> -2.263 </td>\n   <td style=\"text-align:right;\"> 0.024 </td>\n   <td style=\"text-align:right;\"> -0.282 </td>\n   <td style=\"text-align:left;\"> delta d' (condition) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> -0.159 </td>\n   <td style=\"text-align:right;\"> 0.125 </td>\n   <td style=\"text-align:right;\"> -1.278 </td>\n   <td style=\"text-align:right;\"> 0.201 </td>\n   <td style=\"text-align:right;\"> -0.159 </td>\n   <td style=\"text-align:left;\"> delta d' (concordance) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> condition_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> -0.005 </td>\n   <td style=\"text-align:right;\"> 0.125 </td>\n   <td style=\"text-align:right;\"> -0.037 </td>\n   <td style=\"text-align:right;\"> 0.970 </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n   <td style=\"text-align:left;\"> effect of concordance on delta c (condition) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:condition_numeric:concordance_numeric </td>\n   <td style=\"text-align:right;\"> -0.187 </td>\n   <td style=\"text-align:right;\"> 0.249 </td>\n   <td style=\"text-align:right;\"> -0.750 </td>\n   <td style=\"text-align:right;\"> 0.453 </td>\n   <td style=\"text-align:right;\"> -0.187 </td>\n   <td style=\"text-align:left;\"> effect of concordance on delta d' (condition) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nWe can calculate the Signal Detection Theory outcomes by hand as from the summary data shown in @tbl-summary-SDT-data.\n\n\n\n\n::: {#tbl-summary-SDT-data .cell}\n\n```{.r .cell-code}\n# calculate SDT outcomes per condition\nsdt_outcomes <- sdt_data %>%\n  filter(unique_experiment_id == \"1_1\") %>% \n  group_by(sdt_outcome, condition, political_concordance) %>%\n  count() %>% \n  pivot_wider(names_from = sdt_outcome, \n              values_from = n) %>% \n  mutate(\n    z_hit_rate = qnorm(hit / (hit + miss)),\n    z_false_alarm_rate = qnorm(false_alarm / (false_alarm + correct_rejection)),\n    dprime = z_hit_rate - z_false_alarm_rate,\n    c = -1 * (z_hit_rate + z_false_alarm_rate) / 2\n  ) %>% \n  ungroup() \n\nsdt_outcomes %>% \n  kable(booktabs = TRUE, \n        caption = \"Summary data grouped by experimental condition for (Experiment 1 of Paper 1) in our simulated data.\") %>%\n  kable_styling(font_size = 8,  # Set a smaller font size\n                latex_options = c(\"scale_down\")) # Scale down the table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 8px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Summary data grouped by experimental condition for (Experiment 1 of Paper 1) in our simulated data.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> condition </th>\n   <th style=\"text-align:left;\"> political_concordance </th>\n   <th style=\"text-align:right;\"> correct_rejection </th>\n   <th style=\"text-align:right;\"> false_alarm </th>\n   <th style=\"text-align:right;\"> hit </th>\n   <th style=\"text-align:right;\"> miss </th>\n   <th style=\"text-align:right;\"> z_hit_rate </th>\n   <th style=\"text-align:right;\"> z_false_alarm_rate </th>\n   <th style=\"text-align:right;\"> dprime </th>\n   <th style=\"text-align:right;\"> c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:left;\"> concordant </td>\n   <td style=\"text-align:right;\"> 166 </td>\n   <td style=\"text-align:right;\"> 34 </td>\n   <td style=\"text-align:right;\"> 145 </td>\n   <td style=\"text-align:right;\"> 155 </td>\n   <td style=\"text-align:right;\"> -0.0417893 </td>\n   <td style=\"text-align:right;\"> -0.9541653 </td>\n   <td style=\"text-align:right;\"> 0.9123760 </td>\n   <td style=\"text-align:right;\"> 0.4979773 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:left;\"> discordant </td>\n   <td style=\"text-align:right;\"> 244 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 107 </td>\n   <td style=\"text-align:right;\"> 93 </td>\n   <td style=\"text-align:right;\"> 0.0878448 </td>\n   <td style=\"text-align:right;\"> -0.8902469 </td>\n   <td style=\"text-align:right;\"> 0.9780917 </td>\n   <td style=\"text-align:right;\"> 0.4012010 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> intervention </td>\n   <td style=\"text-align:left;\"> concordant </td>\n   <td style=\"text-align:right;\"> 162 </td>\n   <td style=\"text-align:right;\"> 38 </td>\n   <td style=\"text-align:right;\"> 110 </td>\n   <td style=\"text-align:right;\"> 190 </td>\n   <td style=\"text-align:right;\"> -0.3406948 </td>\n   <td style=\"text-align:right;\"> -0.8778963 </td>\n   <td style=\"text-align:right;\"> 0.5372015 </td>\n   <td style=\"text-align:right;\"> 0.6092956 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> intervention </td>\n   <td style=\"text-align:left;\"> discordant </td>\n   <td style=\"text-align:right;\"> 245 </td>\n   <td style=\"text-align:right;\"> 55 </td>\n   <td style=\"text-align:right;\"> 91 </td>\n   <td style=\"text-align:right;\"> 109 </td>\n   <td style=\"text-align:right;\"> -0.1130385 </td>\n   <td style=\"text-align:right;\"> -0.9027348 </td>\n   <td style=\"text-align:right;\"> 0.7896963 </td>\n   <td style=\"text-align:right;\"> 0.5078867 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nBased on this data, we can calculate the average response bias (`(Intercept)`) and sensitivity (`veracity_numeric`), pooled across all conditions; our treatment effects `delta_dprime` (`veracity_numeric:condition_numeric` in the model output) and `delta_c` (`condition_numeric` in the model output) from before, i.e. ignoring/pooling across political concordance; the differences in response bias (`concordance_numeric` in the model output) and sensitivity (`veracity_numeric:concordance_numeric` in the model output) between concordant and discordant items, pooling across control and treatment groups; the moderator effect of convergence, i.e. how much stronger/weaker the effects on response bias (`condition_numeric:concordance_numeric` in the model output) and sensitivity (`veracity_numeric:condition_numeric:concordance_numeric` in the model output) are for concordant items, compared to discordant ones. Table @tbl-moderator-SDT-by-hand shows the results of these by-hand calculations. Comparing the results from the by-hand calculation (@tbl-moderator-SDT-by-hand) and the glm (@tbl-glm-example-experiment1), we note that the results are the same.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# average dprime and c\nSDT_pooled_averages <- sdt_outcomes %>% \n  summarize(across(c(dprime, c), ~mean(.x, na.rm = TRUE), .names = \"average_{.col}\")) \n\n# treatment effect (i.e. main outcomes)\nintervention_effects <- sdt_outcomes %>%\n  select(political_concordance, condition, dprime, c) %>% \n  pivot_wider(\n    names_from = condition, \n    values_from = c(dprime, c)\n  ) %>% \n  mutate(delta_dprime = dprime_intervention - dprime_control, \n         delta_c = c_intervention - c_control) %>% \n  # pool across concordance\n  summarize(across(starts_with(\"delta\"), ~mean(.x, na.rm = TRUE), .names = \"{.col}\")) \n\n# differences in SDT outcomes by convergence\ndifferences_SDT_by_convergence <- sdt_outcomes %>%\n  select(political_concordance, condition, dprime, c) %>% \n  pivot_wider(\n    names_from = political_concordance, \n    values_from = c(dprime, c)\n  ) %>% \n  mutate(delta_dprime = dprime_concordant - dprime_discordant, \n         delta_c = c_concordant - c_discordant) %>% \n  # pool across condition\n  summarize(across(starts_with(\"delta\"), ~mean(.x, na.rm = TRUE), .names = \"{.col}_concordance\")) \n\n# moderator effects\nmoderator_effects <- sdt_outcomes %>%\n  select(political_concordance, condition, dprime, c) %>% \n  pivot_wider(\n    names_from = condition, \n    values_from = c(dprime, c)\n  ) %>% \n  mutate(delta_dprime = dprime_intervention - dprime_control, \n         delta_c = c_intervention - c_control) %>% \n  select(political_concordance, starts_with(\"delta\")) %>% \n  pivot_wider(\n    names_from = political_concordance, \n    values_from = starts_with(\"delta\")\n  ) %>% \n  mutate(moderator_effect_dprime = delta_dprime_concordant - delta_dprime_discordant, \n         moderator_effect_c = delta_c_concordant - delta_c_discordant) %>% \n  select(starts_with(\"moderator\"))\n```\n:::\n\n::: {#tbl-moderator-SDT-by-hand .cell}\n\n```{.r .cell-code}\n# make an overview table \nSDT_outcomes_overview <- bind_cols(SDT_pooled_averages, intervention_effects, \n                                   differences_SDT_by_convergence, \n                                   moderator_effects) %>% \n  pivot_longer(\n    cols = everything(), \n    names_to = \"Outcome\",\n    values_to = \"Value\"\n  ) %>% \n  rounded_numbers()\n\nSDT_outcomes_overview %>% \n  kable(booktabs = TRUE, \n        caption = \"Outcomes from by-hand SDT calculation.\") %>%\n  kable_styling(font_size = 10,  # Set a smaller font size\n                latex_options = c(\"scale_down\")) # Scale down the table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 10px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Outcomes from by-hand SDT calculation.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Outcome </th>\n   <th style=\"text-align:right;\"> Value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> average_dprime </td>\n   <td style=\"text-align:right;\"> 0.804 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> average_c </td>\n   <td style=\"text-align:right;\"> 0.504 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> delta_dprime </td>\n   <td style=\"text-align:right;\"> -0.282 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> delta_c </td>\n   <td style=\"text-align:right;\"> 0.109 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> delta_dprime_concordance </td>\n   <td style=\"text-align:right;\"> -0.159 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> delta_c_concordance </td>\n   <td style=\"text-align:right;\"> 0.099 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> moderator_effect_dprime </td>\n   <td style=\"text-align:right;\"> -0.187 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> moderator_effect_c </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nJust as we do for our main analysis, we estimate the model for each experiment separately and store the results in a common data frame.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Since the loop takes some time, we stored the results in a data frame that we can reload. \nfilename <- \"../data/simulations/concordance_models.csv\" \n\nrun_loop_concordance <- function(data, filename){\n  \n  # make a vector with all unique experiment ids\n  experiments <- data %>% \n    distinct(unique_experiment_id) %>% \n    #slice(1:10) %>% # reduce number of experiments here, to avoid long computation times\n    pull()\n  \n  # only execute the following if the file does NOT exist\n  if (!file.exists(filename)) {\n    \n    time <- system.time({\n      \n      # run one model per experiment and store the results in a common data frame\n      results <- experiments %>%\n        map_dfr(function(x) {\n          \n          # restrict data to only the respective experiment\n          experiment <- data %>% filter(unique_experiment_id == x)\n          \n          # extract paper id\n          paper_id <- unique(experiment$paper_id)\n          \n          # To keep track of progress\n          print(paste(\"calculating model for experiment \", x))\n          \n          model_experiment <- calculate_concordance_model(experiment) %>%\n            mutate(unique_experiment_id = x,\n                   paper_id = paper_id)\n          \n          return(model_experiment)\n        })\n    })\n    \n    write_csv(results, filename)\n    \n    print(paste(\"Elapsed time: \", round(time[3]/60, digits = 2), \" minutes\"))\n  }\n  \n}\n\n# execute function\nrun_loop_concordance(data, filename)\n# read saved model results\nconcordance_model_results <- read_csv(filename)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# give nicer names to estimates\nconcordance_model_results <- concordance_model_results %>% \n  filter(effect == \"fixed\") %>% \n  mutate(\n    # reverse c and delta c estimates\n    SDT_estimate = ifelse(term == \"(Intercept)\" | term == \"condition_numeric\" | term == \"concordance_numeric\" | term == \"condition_numeric:concordance_numeric\", \n                      -1*estimate, estimate),\n    SDT_term = case_when(term == \"(Intercept)\" ~ \"average response bias (c)\", \n                     term == \"veracity_numeric\" ~ \"average sensitivity (d')\", \n                     term == \"condition_numeric\" ~ \"delta c (condition)\",\n                     term == \"concordance_numeric\" ~ \"delta c (concordance)\",\n                     term == \"veracity_numeric:condition_numeric\" ~ \"delta d' (condition)\",\n                     term == \"veracity_numeric:concordance_numeric\" ~ \"delta d' (concordance)\",\n                     term == \"condition_numeric:concordance_numeric\" ~ \"effect of concordance on delta c (condition)\",\n                     term == \"veracity_numeric:condition_numeric:concordance_numeric\" ~ \"effect of concordance on delta d' (condition)\",\n    ),\n    sampling_variance = std.error^2\n  ) \n```\n:::\n\n\n\n\nWe then run the same meta-analytic model as for the main analysis, but on the moderator effect estimates. @tbl-concordance-individual-level shows the results of these models.\n\n\n\n\n::: {#tbl-concordance-individual-level .cell}\n\n```{.r .cell-code}\n# model for delta dprime\nconcordance_delta_dprime <- calculate_models(data = concordance_model_results %>% \n                                   filter(SDT_term == \"effect of concordance on delta d' (condition)\"), \n                                 yi = SDT_estimate, \n                                 vi = sampling_variance, robust = TRUE)\n\n# model for delta c\nconcordance_delta_c <- calculate_models(data = concordance_model_results %>% \n                                   filter(SDT_term == \"effect of concordance on delta c (condition)\"), \n                                 yi = SDT_estimate, \n                                 vi = sampling_variance, robust = TRUE)\n\n\nmodelsummary::modelsummary(list(\"Delta d'\" = concordance_delta_dprime, \n                                \"Delta c\" = concordance_delta_c\n                                ), \n                           title = \"Moderator analysis for politicial concordance based on an individual-level estimates\",\n                           stars = TRUE,\n                           output = \"kableExtra\",\n                           coef_rename = c(\"overall\" = \"Effect of political concordance\")\n                           ) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n<caption>Moderator analysis for politicial concordance based on an individual-level estimates</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Delta d' </th>\n   <th style=\"text-align:center;\"> Delta c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Effect of political concordance </td>\n   <td style=\"text-align:center;\"> −0.002 </td>\n   <td style=\"text-align:center;\"> 0.009 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.055) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.029) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 21 </td>\n   <td style=\"text-align:center;\"> 21 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> 5.1 </td>\n   <td style=\"text-align:center;\"> −20.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> 8.2 </td>\n   <td style=\"text-align:center;\"> −17.2 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n##### ii. Running separate baseline models for concordance\n\nIf we encounter serious convergence issues by integrating the moderator variable in the individual-level model, we will use an alternative strategy. It consists in calculating separate models for concordant and discordant items, and then running a meta-regressions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make two data frames for the two conditions\ndata_concordant <- data %>% filter(political_concordance == \"concordant\")\ndata_discordant <- data %>% filter(political_concordance == \"discordant\")\n\nrun_loop(data = data_concordant, filename = \"../data/simulations/concordant_data.csv\")\nrun_loop(data = data_discordant, filename = \"../data/simulations/discordant_data.csv\")\n\n# read saved model results\nconcordant_results <- read_csv(\"../data/simulations/concordant_data.csv\")\ndiscordant_results <- read_csv(\"../data/simulations/discordant_data.csv\")\n\nresults <- bind_rows(concordant_results %>% \n                       mutate(political_concordance = \"concordant\"), \n                     discordant_results %>% \n                       mutate(political_concordance = \"discordant\")\n                     )\n```\n:::\n\n\n\n\nThis procedure is basically the same as for between-experiment variables (see next section) and run a meta-regression, but there is a slight difference in the meta-regression model specifications: In the case of political concordance, our outcome data frame on which we run the meta-analysis contains two observations per experiment–one for discordant, the other for concordant items. We want to account for this dependency structure with a slightly different random effects structure, where observations are nested in experiments.\n\n@tbl-concordance-separate-baseline-model shows the outcome of this meta-regression based on separate baseline estimates for concordant and discordant news items. In our simulated data--where no true moderator effect was modeled--these estimates are larger than the once we obtain from the intregrated individual-level model (@tbl-concordance-individual-level), but reassuringly they are not significant in either case.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add an observation identifier\nresults <- results %>% \n  mutate(observation_id = 1:nrow(.))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# give nicer names to estimates\nresults <- results %>% \n  filter(effect == \"fixed\") %>% \n  mutate(\n    # reverse c and delta c estimates\n    SDT_estimate = ifelse(term == \"(Intercept)\" | term == \"condition_numeric\", \n                      -1*estimate, estimate),\n    SDT_term = case_when(term == \"(Intercept)\" ~ \"average response bias (c)\", \n                     term == \"veracity_numeric\" ~ \"average sensitivity (d')\", \n                     term == \"condition_numeric\" ~ \"delta c\",\n                     term == \"veracity_numeric:condition_numeric\" ~ \"delta d'\",\n    ),\n    sampling_variance = std.error^2\n  ) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate meta models for the concordance variable\nmeta_regression_concordance <- function(data, yi, vi, moderator, robust = TRUE) {\n  \n  # provide metafor compatible names\n  metafor_data <- data %>% \n    rename(yi = {{yi}}, \n           vi = {{vi}}, \n           moderator = {{moderator}})\n  \n  # Multilevel random effect model for accuracy\n  model <-  metafor::rma.mv(yi, vi, \n                            mods = ~moderator,\n                            random = ~ 1 | unique_experiment_id / observation_id, \n                            data = metafor_data)\n  \n  return(model)\n  \n  if(robust == TRUE) {\n    # with robust standard errors clustered at the paper level \n    robust_model <- robust(model, cluster = data$paper_id)\n    \n    return(robust_model)\n  }\n}\n```\n:::\n\n::: {#tbl-concordance-separate-baseline-model .cell}\n\n```{.r .cell-code}\nconcordance_delta_dprime <- meta_regression_concordance(data = results %>% \n                                                              filter(SDT_term == \"delta d'\"), \n                                                            yi = SDT_estimate, \n                                                            vi = sampling_variance, \n                                                            moderator = political_concordance,\n                                                            robust = TRUE)\n\nconcordance_delta_c <- meta_regression_concordance(data = results %>% \n                                                              filter(SDT_term == \"delta c\"), \n                                                            yi = SDT_estimate, \n                                                            vi = sampling_variance, \n                                                            moderator = political_concordance,\n                                                            robust = TRUE)\n\nmodelsummary::modelsummary(list(\"Delta d'\" = concordance_delta_dprime, \n                                \"Delta c\" = concordance_delta_c\n                                ), \n                           stars = TRUE,\n                           title = \"Moderator analysis for political concordance based on a meta-regression\",\n                           output = \"kableExtra\"\n                           )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n<caption>Moderator analysis for political concordance based on a meta-regression</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Delta d' </th>\n   <th style=\"text-align:center;\"> Delta c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> intercept </td>\n   <td style=\"text-align:center;\"> 0.522*** </td>\n   <td style=\"text-align:center;\"> 0.485*** </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.038) </td>\n   <td style=\"text-align:center;\"> (0.025) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> moderatordiscordant </td>\n   <td style=\"text-align:center;\"> 0.011 </td>\n   <td style=\"text-align:center;\"> 0.021 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.029) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.015) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 44 </td>\n   <td style=\"text-align:center;\"> 44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> −37.5 </td>\n   <td style=\"text-align:center;\"> −96.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> −30.4 </td>\n   <td style=\"text-align:center;\"> −89.6 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n#### b. Between-experiment variables\n\nThe main between-experiment variable we will look at here is interventions type. In our simulated data, we made up three intervention types (\"literacy tips\", \"priming\", \"warning labels\"). We run a meta-regression, in which we add intervention type as a covariate to the meta-analytic model from the main analysis. The results of this analaysis in our simulated data--where no true moderator effect was modeled--can be found in @tbl-intervention-type-moderator.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# we add the intervention types to the effect sizes data frame with the SDT outcomes\n\n# get interventions of all experiments\ndata_intervention_types <- data %>% \n  group_by(unique_experiment_id) %>% \n  # Get all experiments\n  reframe(intervention_type = unique(intervention_type)) \n\n# add intervention types to data\nmoderator_data <- left_join(model_results, data_intervention_types)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate meta models\nmeta_regression <- function(data, yi, vi, moderator, robust = TRUE) {\n  \n  # provide metafor compatible names\n  metafor_data <- data %>% \n    rename(yi = {{yi}}, \n           vi = {{vi}}, \n           moderator = {{moderator}})\n  \n  # Multilevel random effect model for accuracy\n  model <-  metafor::rma.mv(yi, vi, \n                            mods = ~moderator,\n                            random = ~ 1 | paper_id / unique_experiment_id, \n                            data = metafor_data)\n  \n  return(model)\n  \n  if(robust == TRUE) {\n    # with robust standard errors clustered at the paper level \n    robust_model <- robust(model, cluster = data$paper_id)\n    \n    return(robust_model)\n  }\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# meta-regression for delta dprime\ninterventiontype_delta_dprime <- meta_regression(data = moderator_data %>% \n                                  filter(SDT_term == \"delta d'\"), \n                                yi = estimate, \n                                vi = sampling_variance, \n                                moderator = intervention_type,\n                                robust = TRUE)\n\n# meta-regression for c\ninterventiontype_delta_c <- meta_regression(data = moderator_data %>% \n                                  filter(SDT_term == \"delta c\"), \n                                yi = estimate, \n                                vi = sampling_variance, \n                                moderator = intervention_type,\n                                robust = TRUE)\n```\n:::\n\n::: {#tbl-intervention-type-moderator .cell}\n\n```{.r .cell-code}\nmodelsummary::modelsummary(list(\"Delta d'\" = interventiontype_delta_dprime, \n                                \"Delta c\" = interventiontype_delta_c\n                                ), \n                           stars = TRUE,\n                           output = \"kableExtra\",\n                           title = \"Moderator analysis for intervention type\"\n                           )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n<caption>Moderator analysis for intervention type</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Delta d' </th>\n   <th style=\"text-align:center;\"> Delta c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> intercept </td>\n   <td style=\"text-align:center;\"> 0.101* </td>\n   <td style=\"text-align:center;\"> −0.078* </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.046) </td>\n   <td style=\"text-align:center;\"> (0.032) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> moderatorliteracy tips </td>\n   <td style=\"text-align:center;\"> 0.001 </td>\n   <td style=\"text-align:center;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.042) </td>\n   <td style=\"text-align:center;\"> (0.021) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> moderatorpriming </td>\n   <td style=\"text-align:center;\"> 0.000 </td>\n   <td style=\"text-align:center;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.005) </td>\n   <td style=\"text-align:center;\"> (0.005) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> moderatorwarning labels </td>\n   <td style=\"text-align:center;\"> −0.008 </td>\n   <td style=\"text-align:center;\"> −0.006 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.046) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.023) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 52 </td>\n   <td style=\"text-align:center;\"> 52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> −76.2 </td>\n   <td style=\"text-align:center;\"> −135.3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> −64.5 </td>\n   <td style=\"text-align:center;\"> −123.6 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n## Sensitivity Analysis\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsensitivity_data <- read_csv(\"../data/simulations/sensitivity_analysis.csv\")\n```\n:::\n\n\n\n\nSince we are running a meta-analysis based on a systematic review, we cannot control the final sample size. To have rough estimate on the statistical power we anticipate our study to have, we ran a sensitivity analysis based on a simulation. For the simulation, we--conservatively--assumed that the meta-analysis sample will consist of 10 papers. We assumed that each paper has between 1 and 4 experiments, and each experiment can have between two and four experimental arms (one of which is always the control condition). For each experimental arm, we assumed a sample size of 100 participants. The number of experiments per paper and arms per experiments was chosen randomly for each study. We further assumed that participants always saw 5 true and 5 false news. For details about other parameter assumptions, see the parameter list specified above. Although our final sample of papers will probably have properties quite different from what we assumed here, we believe these assumptions are rather conservative.\n\nIn our simulations, we varied the values (small = 0.2, medium = 0.5, large = 0.8) for the true effect sizes for d' and c in the data. For each combination of the two effect sizes, we ran 100 iterations, i.e. 100 times we generated a different sample of 10 papers, and ran our meta-analysis on that sample (900 different meta-analyses in total). The aim of the sensitivity analysis consists in checking for how many of these 100 meta-analyses per combination we find a significant effect. The share of analyses that detect the true effect is the statistical power.\n\nAs shown in @fig-sensitivity-dprime for d' and in @fig-sensitivity-c for c, even for very small effect sizes (0.2), we find statistical power greater than 90%, given our assumptions. For d', the value of c does not appear to affect the statistical power. For c, a low d' (0.2) appears to yield slightly lower statistical power than a medium (0.5) or large (0.8) d.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# specify significance\nalpha <- 0.05\n\nplot_data <- sensitivity_data %>% \n  mutate(significant = ifelse(p.value < alpha, TRUE, FALSE)) %>% \n  group_by(parameter_delta_d_prime, parameter_delta_c) %>% \n  summarise(power = mean(significant)) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(plot_data, \n       aes(x = parameter_delta_d_prime, y = power, color = as.factor(parameter_delta_c))) +\n  geom_point(size = 1.5, alpha = 1) +\n  geom_line(size = 1, alpha = 0.3) + \n  # add a horizontal line at 90%, our power_threshold\n  geom_hline(aes(yintercept = .9), linetype = 'dashed') + \n  # Prettify!\n  theme_minimal() + \n  scale_colour_viridis_d(option = \"plasma\", begin = 0.4, end = 0.7) + \n  scale_y_continuous(labels = scales::percent) + \n  labs(x = 'True effect size', y = 'Power', \n       title = \"Power Curve for Delta d'\")\n```\n\n::: {.cell-output-display}\n![Results of sensitivity analysis for Delta d'. The plot shows the power curve, i.e. the share of statistically significant effects across 100 simulated meta-analyses for each pair of values of d' (x-axis) and c (color legend).](preregistration_files/figure-html/fig-sensitivity-dprime-1.png){#fig-sensitivity-dprime width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot results\nggplot(plot_data, \n       aes(x = parameter_delta_c, y = power, color = as.factor(parameter_delta_d_prime))) +\n  geom_point(size = 1.5, alpha = 0.5) +\n  geom_line(size = 1, alpha = 0.3) + \n  # add a horizontal line at 90%, our power_threshold\n  geom_hline(aes(yintercept = .9), linetype = 'dashed') + \n  # Prettify!\n  theme_minimal() + \n  scale_colour_viridis_d(option = \"plasma\") + \n  scale_y_continuous(labels = scales::percent) + \n  labs(x = 'True effect size', y = 'Power', \n       title = \"Power Curve for Delta c\")\n```\n\n::: {.cell-output-display}\n![Results of sensitivity analysis for Delta c. The plot shows the power curve, i.e. the share of statistically significant effects across 100 simulated meta-analyses for each pair of values of c (x-axis) and d' (color legend).](preregistration_files/figure-html/fig-sensitivity-c-1.png){#fig-sensitivity-c width=672}\n:::\n:::\n\n\n\n\n## Parameter Recovery\n\nInstead of only checking whether our models find a significant effect or not, we also descriptively check how well our model recovers the data generating parameters across the different samples.\n\nAs shown in Figure \\@ref(fig:sensitivity-parameter-dprime) for d' and Figure \\@ref(fig:sensitivity-parameter-c) for c, we find that the distributions of meta-analytic estimates across the 100 samples per pair of effect sizes are centered around the true data generating parameter when the effect size is small (0.2). With an increasing true effect size, however, the estiamte distributions tend to be shifted to the left of the parameter, which suggests that our models consistently underestimate the true effect for larger effect sizes.\n\nOverall, our simulation suggests that (i) given conservative sample size assumptions, we will have large enough statistical power to detect even small effects, and (ii) that our model might slightly underestimate larger true effect sizes, which makes it a conservative estimator.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# custom function for grid labels\ncustom_labeller <- labeller(\n  parameter_delta_c = function(x) paste(\"Delta c:\", x),\n  parameter_delta_d_prime = function(x) paste(\"Delta d':\", x)\n)\n\n# plot Delta d' estimates\nggplot(sensitivity_data %>% filter(term == \"delta d'\"), aes(x = estimate)) +\n  geom_histogram() +\n  geom_vline(aes(xintercept = parameter_delta_d_prime), linetype = \"dotted\", color = \"black\") +\n  labs(x = \"Estimate for Delta d'\") + \n  facet_grid(rows = vars(parameter_delta_c), cols = vars(parameter_delta_d_prime), \n    labeller = custom_labeller)\n```\n\n::: {.cell-output-display}\n![Distributions of Delta d' across simulated meta-analyses. The plot shows the distribution of meta-analytic estimates, for each combination of Delta d' and Delta c values.](preregistration_files/figure-html/fig-sensitivity-parameter-dprime-1.png){#fig-sensitivity-parameter-dprime width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sensitivity_data %>% filter(term == \"delta c\"), aes(x = estimate)) +\n  geom_histogram() +\n  geom_vline(aes(xintercept = parameter_delta_c), linetype = \"dotted\", color = \"black\") +\n  labs(x = \"Estimate for Delta c\") + \n  facet_grid(cols = vars(parameter_delta_c), rows = vars(parameter_delta_d_prime), \n    labeller = custom_labeller)\n```\n\n::: {.cell-output-display}\n![Distributions of Delta c across simulated meta-analyses. The plot shows the distribution of meta-analytic estimates, for each combination of Delta c and Delta d' values.](preregistration_files/figure-html/fig-sensitivity-parameter-c-1.png){#fig-sensitivity-parameter-c width=672}\n:::\n:::\n\n\n\n\n# Data availability\n\nAll simulation data used in this pre-registration is available on the OSF project (https://osf.io/wtxq3/) page or on github (https://github.com/janpfander/meta_interventions_news). \n\n::: {.callout-warning}\nThe project now lives in a new repository: [https://github.com/janpfander/meta_misinformation_interventions](https://github.com/janpfander/meta_misinformation_interventions).\n:::\n\n# Code availability\n\nAll code used to generate this pre-registration and to run the simulations is available on the OSF project (https://osf.io/wtxq3/) page or on github (https://github.com/janpfander/meta_interventions_news). \n\n::: {.callout-warning}\nThe project now lives in a new repository: [https://github.com/janpfander/meta_misinformation_interventions](https://github.com/janpfander/meta_misinformation_interventions).\n:::\n\n# References\n\n::: {#refs}\n:::\n\n# Appendix\n\n## From basic Signal Detection Theory (SDT) to mixed models step-by-step {#sec-step-by-step}\n\nIn this appendix, we explain step-by-step how to go from a by-hand to a generalized linear mixed model (glmm) Signal Detection Theory (SDT) analysis.\n\n### Basic Signal Detection Theory\n\nAfter having classified instances of news ratings according to SDT terminology (@tbl-sdt-vocabulary), we can manually calculate SDT outcomes. @tbl-by-hand-sdt-experiment1 shows by-hand calculated SDT outcomes for the first experiment of our simulated meta-analysis sample.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pick a single experiment\ndata_experiment_1 <- sdt_data %>% \n  filter(unique_experiment_id == \"1_1\")\n\n# calculate SDT outcomes per condition\nsdt_outcomes <- data_experiment_1 %>% \n  group_by(sdt_outcome, condition) %>%\n  count() %>% \n  pivot_wider(names_from = sdt_outcome, \n              values_from = n) %>% \n  mutate(\n    z_hit_rate = qnorm(hit / (hit + miss)),\n    z_false_alarm_rate = qnorm(false_alarm / (false_alarm + correct_rejection)),\n    dprime = z_hit_rate - z_false_alarm_rate,\n    c = -1 * (z_hit_rate + z_false_alarm_rate) / 2\n  ) %>% \n  ungroup()\n```\n:::\n\n::: {#tbl-by-hand-sdt-experiment1 .cell}\n\n```{.r .cell-code}\nsdt_outcomes %>% \n  rounded_numbers() %>% \n  kable(\n    caption = \"SDT outcomes calculated by-hand for Experiment 1 of simulated data.\",\n    booktabs = TRUE) %>%\n  kable_styling(font_size = 8,  # Set a smaller font size\n                latex_options = c(\"scale_down\")) # Scale down the table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 8px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">SDT outcomes calculated by-hand for Experiment 1 of simulated data.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> condition </th>\n   <th style=\"text-align:right;\"> correct_rejection </th>\n   <th style=\"text-align:right;\"> false_alarm </th>\n   <th style=\"text-align:right;\"> hit </th>\n   <th style=\"text-align:right;\"> miss </th>\n   <th style=\"text-align:right;\"> z_hit_rate </th>\n   <th style=\"text-align:right;\"> z_false_alarm_rate </th>\n   <th style=\"text-align:right;\"> dprime </th>\n   <th style=\"text-align:right;\"> c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:right;\"> 410 </td>\n   <td style=\"text-align:right;\"> 90 </td>\n   <td style=\"text-align:right;\"> 252 </td>\n   <td style=\"text-align:right;\"> 248 </td>\n   <td style=\"text-align:right;\"> 0.010 </td>\n   <td style=\"text-align:right;\"> -0.915 </td>\n   <td style=\"text-align:right;\"> 0.925 </td>\n   <td style=\"text-align:right;\"> 0.453 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> intervention </td>\n   <td style=\"text-align:right;\"> 407 </td>\n   <td style=\"text-align:right;\"> 93 </td>\n   <td style=\"text-align:right;\"> 201 </td>\n   <td style=\"text-align:right;\"> 299 </td>\n   <td style=\"text-align:right;\"> -0.248 </td>\n   <td style=\"text-align:right;\"> -0.893 </td>\n   <td style=\"text-align:right;\"> 0.645 </td>\n   <td style=\"text-align:right;\"> 0.570 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nOur treatment effects are the differences between the control and treatment group. We therefor call them `delta_dprime` and `delta_c` here (see @tbl-by-hand-outcomes-experiment1).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntreatment_effects <- sdt_outcomes %>%\n  select(condition, dprime, c) %>% \n  pivot_wider(\n    names_from = condition, \n    values_from = c(dprime, c)\n  ) %>% \n  mutate(delta_dprime = dprime_intervention - dprime_control, \n         delta_c = c_intervention - c_control) %>%\n  select(starts_with(\"delta\"))\n```\n:::\n\n::: {#tbl-by-hand-outcomes-experiment1 .cell}\n\n```{.r .cell-code}\ntreatment_effects %>% \n  rounded_numbers() %>% \n  kable(\n    caption = \"SDT treatment effects calculated by-hand for Experiment 1 of simulated data.\",\n    booktabs = TRUE) %>%\n  kable_styling(font_size = 8,  # Set a smaller font size\n                latex_options = c(\"scale_down\")) # Scale down the table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 8px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">SDT treatment effects calculated by-hand for Experiment 1 of simulated data.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> delta_dprime </th>\n   <th style=\"text-align:right;\"> delta_c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> -0.281 </td>\n   <td style=\"text-align:right;\"> 0.118 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n#### b. SDT in Generalized Mixed Model (glm)\n\nTo obtain test statistics for these outcomes, we can do the equivalent analysis in a generalized linear model (glm), using a probit link function. We use deviation coding for our veracity (fake = -0.5, true = 0.5) and condition (-0.5 = control, 0.5 = intervention) variables. @tbl-glm-experiment1-appendix shows the results of the glm.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run model\nmodel_glm <- glm(accuracy ~ veracity_numeric*condition_numeric, data = data_experiment_1, family = binomial(link = \"probit\"))\n\n# Tidy the model and add the SDT_term column\nmodel_results <- tidy(model_glm, conf.int = TRUE) %>%\n  mutate(SDT_term = case_when(\n    term == \"(Intercept)\" ~ \"Average c (pooled across all conditions)\",\n    term == \"veracity_numeric\" ~ \"Average d' (pooled across all conditions)\",\n    term == \"condition_numeric\" ~ \"Delta c (change in response bias between control and treatment)\",\n    term == \"veracity_numeric:condition_numeric\" ~ \" Delta d' (change in sensitivity between control and treatment)\",\n    TRUE ~ \"Other\"\n  ), \n  # reverse c and delta c estimates\n  SDT_estimate = ifelse(term == \"(Intercept)\" | term == \"condition_numeric\", \n                        -1*estimate, estimate)\n  )\n```\n:::\n\n::: {#tbl-glm-experiment1-appendix .cell}\n\n```{.r .cell-code}\n# Create a table with kable\nmodel_results %>%\n  select(term, estimate, p.value, SDT_estimate, SDT_term) %>%\n  kable(\n    caption = \"Summary of glm results for Experiment 1 of simulated data\",\n    col.names = c(\"Term\", \"Estimate\", \"p-value\", \"SDT Estiamte\", \"SDT Term\"),\n    digits = 3,\n    booktabs = TRUE) %>%\n  kable_styling(\n    full_width = FALSE, \n    font_size = 10, \n    latex_options = c(\"scale_down\")\n  ) %>%\n  add_footnote(\n    \"The model coefficients have the interpretations in terms of SDT as presented here in this table because we use deviation coding for our veracity (fake = -0.5, true = 0.5) and condition (-0.5 = control, 0.5 = intervention) variables.\",\n    notation = \"none\"\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 10px; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Summary of glm results for Experiment 1 of simulated data</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Term </th>\n   <th style=\"text-align:right;\"> Estimate </th>\n   <th style=\"text-align:right;\"> p-value </th>\n   <th style=\"text-align:right;\"> SDT Estiamte </th>\n   <th style=\"text-align:left;\"> SDT Term </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -0.512 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.512 </td>\n   <td style=\"text-align:left;\"> Average c (pooled across all conditions) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric </td>\n   <td style=\"text-align:right;\"> 0.785 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.785 </td>\n   <td style=\"text-align:left;\"> Average d' (pooled across all conditions) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.118 </td>\n   <td style=\"text-align:right;\"> 0.053 </td>\n   <td style=\"text-align:right;\"> 0.118 </td>\n   <td style=\"text-align:left;\"> Delta c (change in response bias between control and treatment) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.281 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n   <td style=\"text-align:right;\"> -0.281 </td>\n   <td style=\"text-align:left;\"> Delta d' (change in sensitivity between control and treatment) </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr>\n<td style = 'padding: 0; border:0;' colspan='100%'><sup></sup> The model coefficients have the interpretations in terms of SDT as presented here in this table because we use deviation coding for our veracity (fake = -0.5, true = 0.5) and condition (-0.5 = control, 0.5 = intervention) variables.</td>\n</tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n#### c. SDT in mixed models\n\nHowever, this analysis is naive, because it treats all observations (instances of news ratings) as independent. Yet, participants give several ratings, and news ratings from the same participant are not independent of each other.\n\n##### i. Participant averages\n\nOne simple way to account for this dependency is to compute participant-level outcomes, and using these averages as observations. This way, each participant only contributes one data point. Figure \\@ref(fig:individual-level-plot) shows the distributions of participants' averages for Experiment 1 of the simulated data. To obtain estimates for our treatment effects $\\Delta c$ and $\\Delta d'$, we can then run a linear regression with condition as a predictor (or do a t-test). The results of these regressions are shown in @tbl-by-participant-SDT-regression.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate SDT outcomes per participant\nsdt_participants <- data_experiment_1 %>% \n  drop_na(sdt_outcome) %>% \n  group_by(unique_subject_id, sdt_outcome) %>%\n  count() %>%\n  ungroup() %>% \n  # Note that currently, not all outcomes appear for participants (e.g. if a participant had only hits and false alarms, correct rejections and misses will not appear). This is a problem later, because when we compute hit and miss rates, the categories that are not appearing will be coded as NA, messing up the calculations. To avoid this, we use the complete() function and ensure that outcomes which do not occur are coded as 0. \n  complete(\n    unique_subject_id,\n    sdt_outcome, \n    fill = list(n = 0)\n  ) %>% \n  # since we want the condition variable in our data, we code it back into there\n  left_join(\n    sdt_data %>% select(unique_subject_id, condition) %>% distinct()\n  ) %>%  \n  pivot_wider(names_from = sdt_outcome, \n              values_from = n) %>% \n  # At this point we need to correct for cases when hit rate or false alarm rate take the values of 0 (case in which qnorm(0) = -Inf) or 1 (case in which qnorm(1) = Inf). We follow Batailler in applying log-linear rule correction (Hautus, 1995)\n  mutate(\n    hit = hit + 0.5,\n    miss = miss + 0.5,\n    correct_rejection = correct_rejection + 0.5,\n    false_alarm = false_alarm + 0.5,\n  ) %>% \n  # We can then compute sdt outcomes for each participant\n  mutate(\n    z_hit_rate = qnorm(hit / (hit + miss)),\n    z_false_alarm_rate = qnorm(false_alarm / (false_alarm + correct_rejection)),\n    dprime = z_hit_rate - z_false_alarm_rate,\n    c = -1 * (z_hit_rate + z_false_alarm_rate) / 2\n  ) %>% \n  ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot\n\n# Main plot data: shape data to long format\nplot_data <- sdt_participants %>% \n  pivot_longer(c(dprime, c),\n               names_to = \"outcome\", \n               values_to = \"value\") %>% \n  # make nicer names\n  mutate(outcome = ifelse(outcome == \"dprime\", \"D' (sensitivity)\", \n                          \"C (response bias)\"))\n\n# summary data for labels\n# table \nsummary_data <- plot_data %>% \n  drop_na(value) %>% \n  mutate(valence = ifelse(value > 0, \"positive\", \n                          ifelse(value == 0, \"neutral\", \n                                 \"negative\")\n                          )\n         ) %>% \n  group_by(valence, outcome) %>% \n  summarize(n_subj = n_distinct(unique_subject_id)) %>% \n    pivot_wider(names_from = outcome, \n              values_from = n_subj) %>% \n  # relative frequency\n  ungroup() %>% \n  mutate(\n    rel_dprime = `D' (sensitivity)` / sum(`D' (sensitivity)`),\n    rel_c =  `C (response bias)` / sum(`C (response bias)`)\n    ) %>% \n  pivot_longer(c(rel_dprime, rel_c), \n               names_to = \"outcome\", \n               values_to = \"value\") %>% \n  mutate(outcome = ifelse(outcome == \"rel_dprime\", \"D' (sensitivity)\", \n                          \"C (response bias)\"), \n         label = paste0(round(value, digits = 4)*100, \" %\"),\n         x_position = case_when(valence == \"negative\" ~ -1,\n                                valence == \"neutral\" ~ 0,\n                                valence == \"positive\" ~ 1), \n         y_position = 1.5)\n\n# make plot\nindividual_level_plot <- ggplot(plot_data, aes(x = value, fill = outcome, color = outcome)) +\n  geom_density(alpha = 0.5, adjust = 1.5)+\n  # add line at 0\n  geom_vline(xintercept = 0, \n             linewidth = 0.5, linetype = \"24\", color = \"grey\") +\n  # scale\n  # scale_x_continuous(breaks = seq(from = -1, to = 1, by = 0.2)) +\n  # add labels for share of participants\n  geom_label(inherit.aes = FALSE, data = summary_data,\n             aes(x = x_position, y = y_position, \n                 label = label),\n             alpha = 0.6,\n             color = \"grey50\", size = 3, show.legend = FALSE) +\n  # colors \n  scale_color_viridis_d(option = \"turbo\", begin = 0.25, end = 1)+\n  scale_fill_viridis_d(option = \"turbo\", begin = 0.25, end = 1) +\n  # labels and scales\n  labs(x = \"Z-scores\", y = \"Density\") +\n  guides(fill = FALSE, color = FALSE) +\n  plot_theme +\n  theme(legend.position = \"bottom\",\n        axis.text.y = element_blank(),\n        strip.text = element_text(size = 14)) +\n  facet_wrap(~outcome)\n\n#individual_level_plot\n\n# Save the plot to a file\nggsave(\"individual_level_plot.png\", individual_level_plot, width = 8, height = 6)\n\n# In the RMarkdown file\nknitr::include_graphics(\"individual_level_plot.png\")\n```\n\n::: {.cell-output-display}\n![Distribution of participant-level averages for Experiment 1 of the simulated data. The percentage labels (from left to right) represent the share of participants with a negative score, a score of exactly 0, and a positive score, for both measures respectively. Note that when calculating by-participant averages, we follow @bataillerSignalDetectionApproach2022 in applying log-linear rule correction. This is particularly relevant for cases when the hit rate or the false alarm rate take the values of 0 (case in which qnorm(0) = -Inf) or 1 (case in which qnorm(1) = Inf).](individual_level_plot.png){#fig-individual-level-plot width=1200}\n:::\n:::\n\n::: {#tbl-by-participant-SDT-regression .cell}\n\n```{.r .cell-code}\nmodel_dprime <- lm(dprime ~ condition, data = sdt_participants)\nmodel_c <- lm(c ~ condition, data = sdt_participants)\n\nmodelsummary::modelsummary(list(\"d'\" = model_dprime, \n                                \"c\" = model_c\n                                ), \n                           stars = TRUE,\n                           output = \"kableExtra\",\n                           title = \"SDT outcomes based on a regression on participant-level averages\",\n                           coef_rename = c(\"conditionintervention\" = \"Treatment Effect\"),\n                           )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n<caption>SDT outcomes based on a regression on participant-level averages</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> d' </th>\n   <th style=\"text-align:center;\"> c </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 0.814*** </td>\n   <td style=\"text-align:center;\"> 0.402*** </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.068) </td>\n   <td style=\"text-align:center;\"> (0.038) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Treatment Effect </td>\n   <td style=\"text-align:center;\"> −0.263** </td>\n   <td style=\"text-align:center;\"> 0.101+ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.096) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> (0.054) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 200 </td>\n   <td style=\"text-align:center;\"> 200 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 </td>\n   <td style=\"text-align:center;\"> 0.036 </td>\n   <td style=\"text-align:center;\"> 0.017 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 Adj. </td>\n   <td style=\"text-align:center;\"> 0.031 </td>\n   <td style=\"text-align:center;\"> 0.012 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> 417.5 </td>\n   <td style=\"text-align:center;\"> 186.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> 427.4 </td>\n   <td style=\"text-align:center;\"> 196.0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Log.Lik. </td>\n   <td style=\"text-align:center;\"> −205.768 </td>\n   <td style=\"text-align:center;\"> −90.061 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 0.68 </td>\n   <td style=\"text-align:center;\"> 0.38 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nBy comparing the results of the regression based on participant-level averages (@tbl-by-participant-SDT-regression), to the results of the glm at the rating-level and which glosses over participant dependencies (@tbl-glm-experiment1-appendix), we can see that the estimates for our outcomes $\\Delta c$ and $\\Delta d'$ are slightly different. However, we can account even better for our data structure, and estimate both within and between participant variation separately by using a generalized linear mixed model (glmm).\n\n#### ii. Mixed model SDT\n\nUsing a glm with probit link function as above, we can additionally specify random effects. The result is a generalized linear mixed model (glmm). Adding random effects for participants allows us to model the dependency of data points from the same participant, thereby account for these difference, while not loosing data points as in the participant-averages approach discussed above.\n\n@tbl-glmm-experiment1-appendix shows that, for our simulated experiment 1, the estimates of the glmm are close to, but slightly different from, the initial gml without random effects (@tbl-glm-experiment1-appendix).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sometimes these models take time, so we check that time\ntime <- system.time({\n  mixed_model <- glmer(accuracy ~ veracity_numeric + condition_numeric + \n                         veracity_numeric*condition_numeric +\n                         (1 + veracity_numeric | unique_subject_id),\n                       data = data_experiment_1, \n                       family = binomial(link = \"probit\"))\n})\n\n#print(paste(\"Elapsed time: \", round(time[3]/60, digits = 2), \" minutes\"))\n\n# get a tidy version\nmixed_model <- tidy(mixed_model, conf.int = TRUE)\n```\n:::\n\n::: {#tbl-glmm-experiment1-appendix .cell}\n\n```{.r .cell-code}\n# show results\nmixed_model <- mixed_model %>%\n  mutate(SDT_term = case_when(\n    term == \"(Intercept)\" ~ \"Average c (pooled across all conditions)\",\n    term == \"veracity_numeric\" ~ \"Average d' (pooled across all conditions)\",\n    term == \"condition_numeric\" ~ \"Delta c (change in -response bias between control and treatment)\",\n    term == \"veracity_numeric:condition_numeric\" ~ \" Delta d' (change in sensitivity between control and treatment)\",\n    TRUE ~ \"Other\"\n  ), \n  # reverse c and delta c estimates\n  SDT_estimate = ifelse(term == \"(Intercept)\" | term == \"condition_numeric\", \n                        -1*estimate, estimate)\n  )\n\nmixed_model %>% \n  select(-starts_with(\"conf\")) %>% \n  rounded_numbers() %>% \n  select(-c(effect, group)) %>% \n  kable(\n    caption = \"Results of a generalize linear mixed model (glmm)\",\n    booktabs = TRUE) %>%\n  kable_styling(font_size = 8,  # Set a smaller font size\n                latex_options = c(\"scale_down\")) # Scale down the table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 8px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Results of a generalize linear mixed model (glmm)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:left;\"> SDT_term </th>\n   <th style=\"text-align:right;\"> SDT_estimate </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -0.514 </td>\n   <td style=\"text-align:right;\"> 0.032 </td>\n   <td style=\"text-align:right;\"> -16.175 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:left;\"> Average c (pooled across all conditions) </td>\n   <td style=\"text-align:right;\"> 0.514 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric </td>\n   <td style=\"text-align:right;\"> 0.786 </td>\n   <td style=\"text-align:right;\"> 0.062 </td>\n   <td style=\"text-align:right;\"> 12.711 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:left;\"> Average d' (pooled across all conditions) </td>\n   <td style=\"text-align:right;\"> 0.786 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.119 </td>\n   <td style=\"text-align:right;\"> 0.063 </td>\n   <td style=\"text-align:right;\"> -1.892 </td>\n   <td style=\"text-align:right;\"> 0.059 </td>\n   <td style=\"text-align:left;\"> Delta c (change in -response bias between control and treatment) </td>\n   <td style=\"text-align:right;\"> 0.119 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> veracity_numeric:condition_numeric </td>\n   <td style=\"text-align:right;\"> -0.285 </td>\n   <td style=\"text-align:right;\"> 0.123 </td>\n   <td style=\"text-align:right;\"> -2.312 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n   <td style=\"text-align:left;\"> Delta d' (change in sensitivity between control and treatment) </td>\n   <td style=\"text-align:right;\"> -0.285 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sd__(Intercept) </td>\n   <td style=\"text-align:right;\"> 0.109 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:left;\"> Other </td>\n   <td style=\"text-align:right;\"> 0.109 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> cor__(Intercept).veracity_numeric </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:left;\"> Other </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sd__veracity_numeric </td>\n   <td style=\"text-align:right;\"> 0.090 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:left;\"> Other </td>\n   <td style=\"text-align:right;\"> 0.090 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n",
    "supporting": [
      "preregistration_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}