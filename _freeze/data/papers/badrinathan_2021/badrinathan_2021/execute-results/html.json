{
  "hash": "88537429ca4f071bde8d977ada787448",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Educative Interventions to Combat Misinformation: Evidence from a Field Experiment in India.\"\ndate: \"2021\"\nauthor: \n  - Badrinathan, Sumitra\ncategories:\n  - literacy\nbibliography: ../../../references.bib\nnocite: |\n  @badrinathanEducativeInterventionsCombat2021\ndraft: false \n---\n\n\n\n\n\n\n## Reference\n\n::: {#refs}\n:::\n\n## Intervention\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintervention_info <- tibble(\n    intervention_description = 'The study tested the effect of a literacy intervention with two slightly different variants. At first, all participants in the treatment group received the following : \"Pedagogical intervention: Next, respondents went through a learning module to help inoculate against misinformation. This included an hour-long discussion on encouraging people to verify information along with concrete tools to do so.\" The difference between the two treatment groups was in some of the materials they were presented with: \"Both treatment groups received the pedagogical intervention. However, one group received corrections to four pro-BJP false stories and the other received corrections to four anti-BJP false stories. Besides differences in the stories that were fact-checked, the tips on the flyer remained the same for both treatment groups. The author pooled the conditions in their study as well as in the data we have at hand. We therefor assign a single label (`intervention_label` = \"literacy\") for the treatment.',\n    intervention_selection = NA,\n    intervention_selection_description = 'The author pooled both treatment groups together, after not having found differences in the treatment effect between the two. We follow the author, mostly because both treatment conditions seem sufficiently similar.',\n    # the author measured detection of misinformation, not discernment  \n    originally_identified_treatment_effect = NA,\n    control_format = \"picture\")\n\n# display\nshow_conditions(intervention_info)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> intervention_description </th>\n   <th style=\"text-align:left;\"> intervention_selection_description </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> The study tested the effect of a literacy intervention with two slightly different variants. At first, all participants in the treatment group received the following : &quot;Pedagogical intervention: Next, respondents went through a learning module to help inoculate against misinformation. This included an hour-long discussion on encouraging people to verify information along with concrete tools to do so.&quot; The difference between the two treatment groups was in some of the materials they were presented with: &quot;Both treatment groups received the pedagogical intervention. However, one group received corrections to four pro-BJP false stories and the other received corrections to four anti-BJP false stories. Besides differences in the stories that were fact-checked, the tips on the flyer remained the same for both treatment groups. The author pooled the conditions in their study as well as in the data we have at hand. We therefor assign a single label (`intervention_label` = &quot;literacy&quot;) for the treatment. </td>\n   <td style=\"text-align:left;\"> The author pooled both treatment groups together, after not having found differences in the treatment effect between the two. We follow the author, mostly because both treatment conditions seem sufficiently similar. </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n### Notes\n\nFrom an e-mail exchange with the author, we know that true news were selected from \"mainstream as well as fact checking sites\" and that news were presented in format of \"headline + image in some cases\".\n\nThe author measured detection of misinformation, not discernment. The outcome was only based on the misinformation items.\n\n> \"Receiving this hour-long media literacy intervention did not significantly increase respondents’ ability to identify misinformation on average.\"\n\n## Data Cleaning\n\nRead data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- read_csv(\"badrinathan_2021.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1224 Columns: 339\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (22): po_name, vill_tow_name, near_place, enu_name, sup_name, q12_oth,...\ndbl  (278): Serial.No., DeviceId.x, po_code, Newpo_code, po_pri_nu, enu_code...\nlgl   (37): spd_bn, spd_res_name, spd_vill, spd_emu_info, gp_inf_cons, disp_...\ndttm   (2): StartTime.x, StartTime.y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n\n### `accuracy_raw`, `scale`, `veracity`, Conditions (`intervention_label`, `condition`)\n\nFrom the cleaning document of the author, we can deduce which variables correspond to false and which to true news items.\n\nThe false news items were:\n\ndv1: CCTV : 'cctv' dv2: no terror attacks : 'attacks' dv3 : pulwama fake photos : 'pulwama' dv4 : ganga fake photos : 'ganga' dv5 : fake plastic finger : 'plastic' dv6 : soldier : 'soldier' dv7 : gomutra : 'gomutra' dv8 : rally : 'rally' dv9 : child kidnap : 'kidnap_dv' dv10 : 2000 note : 'note' dv11 : patel statue : 'patel' dv12 : flag on statue of liberty : 'flag' dv13 : evm hacking : 'evm'\n\nThe true news items were:\n\ndv14: man ki baat: 'true1' dv15: pulwama : 'true1'\n\nNote that variables are coded `1` for correct responses (i.e. 1 corresponds to 'not accurate' for false news, and to 'accurate' for true news).\n\nThe data set does not distinguish between the two slightly different treatment groups, as the author pooled them for her analysis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# bring data to long format and recode variables\nlong_d <- d %>% \n  pivot_longer(c(attacks, pulwama, ganga, plastic, soldier, gomutra, rally, \n                 kidnap_dv, note, patel, flag, evm, true1, true2), \n               names_to = \"item\",\n               values_to = \"ratings\") %>% \n  # make an binary 'veracity' variable identifying true and fake\n  mutate(veracity = ifelse(grepl('true', item), 'true', 'false'), \n         # make condition a factor\n         condition = recode_factor(treatment, `0` = \"control\", `1` = \"treatment\"), \n         # add an intervention label\n         intervention_label = ifelse(condition == \"treatment\", \"literacy\", NA),\n         # recode accuracy responses for fake news\n         # so that 1 = rated as accurate (just as is measured for true news)\n         accuracy_raw = ifelse(veracity == 'false', \n                                  ifelse(ratings == 1, 0, 1), \n                                  ratings), \n         scale = \"binary\"\n         )\n\n# check\n# long_d %>% \n#   group_by(item, veracity, treatment, condition) %>% \n#   summarize(n = n(), \n#             mean_rating = mean(ratings, na.rm=TRUE),\n#             mean_accuracy= mean(accuracy_raw, na.rm=TRUE))\n```\n:::\n\n\n\n\n### `news_id`, `news_selection`\n\nIn the previous section, we have already created a news identifier `item`. Here we just rename this identifier.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong_d <- long_d |> \n  mutate(news_id = item, \n         news_selection = \"researchers\")\n```\n:::\n\n\n\n\n\n### Concordance (`concordance`, `partisan_identity`, `news_slant`)\n\nWhile political concordance is not explicitly coded, we can build it from participants' political leaning and the political slant of the news items.\n\nFrom the cleaning document, we know that participants' party id (i.e. pro or contra the governing party) is coded by the variable 'BJP'. The problem is: we don't know what level (0,1) corresponds to which id. By replicating figure 5 (with the replication file accessible online) from the paper, we figured out that 0 = non BJP and 1 = BJP.\n\nWe also know which fake news items are pro-BJP (gomutra, attacks, pulwama, soldier, flag, note) and which fake news items are anti_BJP (cctv, evm, ganga, kidnap_dv, plastic, patel). Regarding true news, combining the cleaning document and the supplement (table D.1), we know that `true1` (man ki baat) = pro BJP; and `true2` (pulwama) = anti BJP.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npro_BJP <- c(\"gomutra\", \"attacks\", \"pulwama\", \"soldier\", \"flag\", \"note\", \"true1\")\n\nlong_d <- long_d %>% \n  # make a binary variable indicating political slant of news\n  mutate(news_slant = ifelse(item %in% pro_BJP, \"pro_BJP\", \"anti_BJP\"),\n         # make a clearer party id variable\n         partisan_identity = recode_factor(BJP, `0` = \"non_BJP\", `1` = \"BJP\"),\n         # combine party id and political slant \n         concordance = case_when(news_slant == \"pro_BJP\" & partisan_identity == \"BJP\" ~ \"concordant\",\n                                 news_slant == \"anti_BJP\" & partisan_identity == \"non_BJP\" ~ \"concordant\", \n                                 TRUE ~ \"discordant\")\n  )\n\n# check \n# long_d %>% select(political_slant, party_id, concordance)\n```\n:::\n\n\n\n\n### `subject_id`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check id \nnrow(d) # n participants (one row per participant)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1224\n```\n\n\n:::\n\n```{.r .cell-code}\nn_distinct(long_d$Serial.No.) # likely the correct variable\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1224\n```\n\n\n:::\n\n```{.r .cell-code}\nlong_d %>% \n  group_by(Serial.No) %>% \n  count() # second check, 14 observations\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,224 × 2\n# Groups:   Serial.No [1,224]\n   Serial.No     n\n       <dbl> <int>\n 1         1    14\n 2         2    14\n 3         4    14\n 4         9    14\n 5        10    14\n 6        12    14\n 7        13    14\n 8        14    14\n 9        16    14\n10        17    14\n# ℹ 1,214 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlong_d <- long_d |> \n  mutate(subject_id = Serial.No.)\n```\n:::\n\n\n\n\n\n### `age`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check age \ntable(long_d$age, useNA = \"always\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33 \n2086 1330 1680 1330 1204  784  770 1148  812  364  616  210  854  112  448  154 \n  34   35   36   37   38   39   40   41   42   43   44   45   48   49   50   51 \n 196  462  154   70  294   42  546   56  182   28   42  322  196   14  196   28 \n  52   53   55   58   59   61   62   64   65   68   85 <NA> \n 112   42   84   28   42   14   14   14   28   14   14    0 \n```\n\n\n:::\n:::\n\n\n\n\n### Identifiers (`country`, `paper_id`, `experiment_id`)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make final data\nbadrinathan_2021 <- long_d %>% \n  mutate(\n    experiment_id = 1,\n    country = \"India\",\n    paper_id = \"Badrinathan_2021\") |> \n  # add_intervention_info \n  bind_cols(intervention_info) |> \n  # reduce to target variables\n  select(any_of(target_variables))\n```\n:::\n\n\n\n\n### Write out data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave_data(badrinathan_2021)\n```\n:::\n",
    "supporting": [
      "badrinathan_2021_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}