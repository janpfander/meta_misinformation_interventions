{
  "hash": "c2043cfd0f1387d6b5d1dc7b79f6da57",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Real Solutions for Fake News? Measuring the Effectiveness of General Warnings and Fact-Check Tags in Reducing Belief in False Stories on Social Media.\"\ndate: \"2020\"\nauthor: \n  - Clayton, Katherine\ncategories:\n  - literacy\nbibliography: ../../../references.bib\nnocite: |\n  @claytonRealSolutionsFake2020\ndraft: false \n---\n\n\n\n\n\n\n## Reference\n\n::: {#refs}\n:::\n\n## Intervention\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintervention_info <- tibble(\n    intervention_description = '\"The experiment used a 2× 3 between-subjects design that also includes a pure control group. Participants were randomly assigned with equal probability to a pure control group or to one of six experimental conditions (see Table 1). We manipulated whether participants were exposed to a general warning about misleading articles or not (middle column of Table 1). We also independently randomized noncontrols into one of three headline conditions: a condition in which no fact-checking tags were presented (first two rows of Table 1), a specific warning condition that included tags labeling articles as “Disputed” (second two rows of Table 1), and a specific warning condition in which they were instead labeled as “Rated false” (last two rows of Table 1).\"',\n    control_selection = \"control_no_warning\",\n    intervention_selection = \"labels_false_no_warning\",\n    intervention_selection_description = \"We believe the warning tag intervention to be more interesting than the general warning intervention. We therefor use only the ones where there is no general warning. We also discard the pure control group in which participants didn't read any news items. There are two types of warning tag interventions: One that labels false articles as 'disputed' and another that labels them as 'rated false'. We will merge these two conditions as they seem sufficiently similar to be part of a warning tag category.\",\n    # the author measured detection of misinformation, not discernment  \n    originally_identified_treatment_effect = NA)\n\nintervention_info |> \n  select(intervention_description, intervention_selection_description) |> \n  kbl()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> intervention_description </th>\n   <th style=\"text-align:left;\"> intervention_selection_description </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> &quot;The experiment used a 2× 3 between-subjects design that also includes a pure control group. Participants were randomly assigned with equal probability to a pure control group or to one of six experimental conditions (see Table 1). We manipulated whether participants were exposed to a general warning about misleading articles or not (middle column of Table 1). We also independently randomized noncontrols into one of three headline conditions: a condition in which no fact-checking tags were presented (first two rows of Table 1), a specific warning condition that included tags labeling articles as “Disputed” (second two rows of Table 1), and a specific warning condition in which they were instead labeled as “Rated false” (last two rows of Table 1).&quot; </td>\n   <td style=\"text-align:left;\"> We believe the warning tag intervention to be more interesting than the general warning intervention. We therefor use only the ones where there is no general warning. We also discard the pure control group in which participants didn't read any news items. There are two types of warning tag interventions: One that labels false articles as 'disputed' and another that labels them as 'rated false'. We will merge these two conditions as they seem sufficiently similar to be part of a warning tag category. </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n### Notes\n\nThe study tested the effect of a literacy intervention. For an overview of the labels we've assigned, see the `intervention_label` column in Table @tbl-clayton-conditions.\n\n\n\n\n::: {#tbl-clayton-conditions .cell}\n::: {.cell-output-display}\n\n\nTable: Table: Participant Counts by Tag and General Warning\n\n|Tag           |General warning |   N|intervention_label         |\n|:-------------|:---------------|---:|:--------------------------|\n|None          |No              | 469|NA                         |\n|None          |Yes             | 424|NA                         |\n|“Disputed”    |No              | 413|labels_disputed_no_warning |\n|“Disputed”    |Yes             | 429|labels_disputed_warning    |\n|“Rated false” |No              | 429|labels_false_no_warning    |\n|“Rated false” |Yes             | 397|labels_false_warning       |\n|Pure control  |NA              | 433|NA                         |\n\n\n:::\n:::\n\n\n\n\n> \"In the pure control group, respondents were exposed to no images, no articles, no general warning, no tags, and no headlines, and proceeded directly to the questions measuring the outcome variable (discussed in the next section).\"\n\"In the general warning condition, participants were shown a message warning them about misleading articles and providing advice for identifying false information (see Online Appendix A for exact wording and design).\"\n\n## Data Cleaning\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define variables to select\ntarget_variables <- c(\n    \"paper_id\", \"experiment_id\", \"subject_id\", \"news_id\", \"country\", \"year\", \n    \"veracity\", \"condition\", \"intervention_label\", \"intervention_description\", \n    \"intervention_selection\",\n    \"intervention_selection_description\",\n    \"control_selection\",\n    \"accuracy_raw\", \"scale\", \"originally_identified_treatment_effect\", \n    \"concordance\", \"partisan_identity\", \"news_slant\", \"age\", \"age_range\", \"identified_via\", \"id\", \n    \"unique_experiment_id\", \"accuracy\"\n  )\n```\n:::\n\n\n\n\nRead data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import data \nload(\"clayton_2020.RData\")\n\n# by default, the data frame is called \"table\" \n# rename\n\ndata <- table\n```\n:::\n\n\n\n\n### Interventions\n\nWe first need to indentiy the different experimental conditions. This is a bit tricky because the documentation is bad.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cross-reading paper and stata code, these seem to be the relevant variables for condition\ndata %>% \n  select(cond, nocorr_condition, disputed_condition, false_condition, \n                   flag_cond, purecontrol, warning, nowarning)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,994 × 8\n    cond nocorr_condition disputed_condition false_condition flag_cond \n   <dbl>            <dbl>              <dbl>           <dbl> <hvn_lbll>\n 1     4                0                  1               0  2        \n 2     2                1                  0               0  1        \n 3     5                0                  1               0  2        \n 4     1                0                  0               0 NA        \n 5     4                0                  1               0  2        \n 6     3                1                  0               0  1        \n 7     2                1                  0               0  1        \n 8     2                1                  0               0  1        \n 9     1                0                  0               0 NA        \n10     4                0                  1               0  2        \n# ℹ 2,984 more rows\n# ℹ 3 more variables: purecontrol <dbl>, warning <dbl>, nowarning <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\n# cross-check sample sizes with what is reported in the paper to be sure these are the conditions\ndata %>% \n  group_by(cond, nocorr_condition, disputed_condition, false_condition, \n                   flag_cond, purecontrol, warning, nowarning) %>% \n  summarize(n_per_condition = n()) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'cond', 'nocorr_condition',\n'disputed_condition', 'false_condition', 'flag_cond', 'purecontrol', 'warning'.\nYou can override using the `.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 9\n# Groups:   cond, nocorr_condition, disputed_condition, false_condition,\n#   flag_cond, purecontrol, warning [7]\n   cond nocorr_condition disputed_condition false_condition flag_cond \n  <dbl>            <dbl>              <dbl>           <dbl> <hvn_lbll>\n1     1                0                  0               0 NA        \n2     2                1                  0               0  1        \n3     3                1                  0               0  1        \n4     4                0                  1               0  2        \n5     5                0                  1               0  2        \n6     6                0                  0               1  3        \n7     7                0                  0               1  3        \n# ℹ 4 more variables: purecontrol <dbl>, warning <dbl>, nowarning <dbl>,\n#   n_per_condition <int>\n```\n\n\n:::\n:::\n\n\n\n\nBased on this information, we build a condition variable with more meaningful value labels.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make new easy-to-read condition variable\ndata <- data %>% \n  mutate(condition = case_when(cond == 1 ~ \"pure_control\", \n                               cond == 2 ~ \"control_no_warning\", \n                               cond == 3 ~ \"control_warning\", \n                               cond == 4 ~ \"disputed_no_warning\",\n                               cond == 5 ~ \"disputed_warning\", \n                               cond == 6 ~ \"false_no_warning\", \n                               cond == 7 ~ \"false_warning\")\n  )\n\n# check for correct sample size\ndata %>% group_by(condition) %>% summarise(n = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 2\n  condition               n\n  <chr>               <int>\n1 control_no_warning    469\n2 control_warning       424\n3 disputed_no_warning   413\n4 disputed_warning      429\n5 false_no_warning      429\n6 false_warning         397\n7 pure_control          433\n```\n\n\n:::\n:::\n\n\n\n\n### Veracity\n\nAs a next step, we need to identify which variables code instances of news ratings\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# trying to identify news ratings  \ndata %>% select(belief_old_fake_news, belief_real_news, real_civil_war_belief,\n                 real_syria_belief, real_gorsuch_belief, draft_belief, bee_belief, \n                 chaf_belief, protester_belief, marines_belief, fbiagent_belief) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,994 × 11\n   belief_old_fake_news belief_real_news real_civil_war_belief real_syria_belief\n                  <dbl>            <dbl>                 <dbl>             <dbl>\n 1                 1.75             2.60                     3                 3\n 2                 2.75             3.60                     3                 4\n 3                 1.25             4                        3                 3\n 4                 2                3.60                     2                 3\n 5                 1.75             3.20                     3                 4\n 6                 1                4                        3                 4\n 7                 2                4                        3                 4\n 8                 2.25             3.20                     2                 4\n 9                 2                3.80                     2                 2\n10                 2.25             2.80                     1                 4\n# ℹ 2,984 more rows\n# ℹ 7 more variables: real_gorsuch_belief <dbl>, draft_belief <dbl>,\n#   bee_belief <dbl>, chaf_belief <dbl>, protester_belief <dbl>,\n#   marines_belief <dbl>, fbiagent_belief <dbl>\n```\n\n\n:::\n:::\n\n\n\n\nIt seems that all true news are preceded by 'real'. Next, we bring the data into long format to build a veracity variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# bring data to long format\nlong_data <- data %>% \n  # make an id variable\n  mutate(id = 1:nrow(.)) %>% \n  pivot_longer(c(real_civil_war_belief, real_syria_belief, real_gorsuch_belief, \n                 draft_belief, bee_belief, chaf_belief, protester_belief, \n                 marines_belief, fbiagent_belief), \n               names_to = \"item\",\n               values_to = \"ratings\") %>% \n  # make an binary 'veracity' variable identifying true and fake\n  mutate(veracity = ifelse(grepl('real', item), 'true', 'false'))\n\n# check that veracity corresponds to correct items\n# long_data %>% \n#   group_by(item, veracity) %>% \n#   summarize(n = n())\n```\n:::\n\n\n\n\n### News id\n\nIn the previous section, we have already created a news identifier `item`. Here we just rename this identifier.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong_data <- long_data |> \n  mutate(news_id = item)\n```\n:::\n\n\n\n\n### Age\n\nAge is only provided in bins. We make a cleaner version of the variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract labels from the variable's attributes\nlabels <- attr(long_data$agegroup, \"labels\")\n\n# Use the numeric values as levels and their names as labels\nlong_data <- long_data %>%\n  mutate(age_range = factor(agegroup, \n                      levels = labels, \n                      labels = names(labels)))\n```\n:::\n\n\n\n\nBased on this bin variable, we take the age category mid-point as a proxy for age.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define midpoints for each age group\nage_midpoints <- c(\n  \"Under 18\" = 17,             \n  \"18 - 24\" = (18 + 24) / 2,\n  \"25 - 34\" = (25 + 34) / 2,\n  \"35 - 44\" = (35 + 44) / 2,\n  \"45 - 54\" = (45 + 54) / 2,\n  \"55 - 64\" = (55 + 64) / 2,\n  \"65 - 74\" = (65 + 74) / 2,\n  \"75 - 84\" = (75 + 84) / 2,\n  \"85 or older\" = 85          \n)\n\n# Map numeric codes to labels, then to midpoints\nage_midpoints <- setNames(as.numeric(age_midpoints), names(labels))\n\n# Replace agegroup with midpoints\nlong_data <- long_data %>%\n  mutate(age = ifelse(!is.na(age_range), age_midpoints[age_range], NA))\n\n# check\n# long_data %>% \n#   select(age, age_range)\n```\n:::\n\n\n\n\n### Clean data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make final data\nclayton_2020 <- long_data %>% \n  mutate(\n    subject_id = id,\n    # make sure that the control conditions has no intervention label\n    intervention_label = ifelse(str_detect(condition, \"control\"),\n                                NA,\n                                paste0(\"labels_\", condition)), \n    # keep different labels for control conditions, code treatment as \"treatment\"\n    condition = ifelse(str_detect(condition, \"control\"), condition, \"treatment\"),\n    accuracy_raw = ratings,\n    experiment_id = 1,\n    scale = 4, \n    country = \"United States\",\n    paper_id = \"Clayton_2020\") %>% \n    # add_intervention_info \n  bind_cols(intervention_info) |> \n  select(any_of(target_variables))\n\n\n# check conditions\n# clayton_2020 |>\n#   group_by(condition) |>\n#   reframe(unique(intervention_label))\n```\n:::\n\n\n\n\n### Write out data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave_data(clayton_2020)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}