{
  "hash": "4c04f5cc598a9d99e1f31d8704f01855",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: People Are Skeptical of Headlines Labeled as AI-Generated, Even If True or Human-Made, Because They Assume Full AI Automation.\ndate: \"2024\"\nauthor: \n  - Altay, Sacha\ncategories:\n  - warning label\nbibliography: ../../../references.bib\nnocite: |\n  @altayPeopleAreSkeptical2024\ndraft: false \n---\n\n\n\n\n\n\n## Reference\n\n::: {#refs}\n:::\n\n## Intervention\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintervention_info <- tibble(\n    intervention_description = 'In Study 1, participants were randomly assigned to one of the five following conditions: (i) the Control Condition in which no headline was labeled, (ii) the correct label condition in which all AI-generated headlines were labeled (`intervention_label` = \"label_Correct\"), (iii) the missing label condition in which only half of AI-generated headlines were labeled (`intervention_label` = \"label_Missing\"), (iv) the noisy label condition in which half of AI-generated headlines were labeled and half of human-generated headlines were mislabeled (`intervention_label` = \"label_Noise \"), and (v) the false label condition in which false headlines were labeled as false (`intervention_label` = \"label_FalseLabel\")',\n    intervention_selection = \"label_FalseLabel\",\n    intervention_selection_description = 'The paper\\'s main goal is to test how AI labels affect accuracy judgments. However, this is not the main interest of our study. We will therefor reduce the treatment to the condition in Study 1 where false headlines are labeled as false (`intervention_label` = \"label_FalseLabel\").',\n    #the authors did not measure discernment \n    originally_identified_treatment_effect = NA)\n\nintervention_info |> \n  select(intervention_description, intervention_selection_description) |> \n  kbl()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> intervention_description </th>\n   <th style=\"text-align:left;\"> intervention_selection_description </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> In Study 1, participants were randomly assigned to one of the five following conditions: (i) the Control Condition in which no headline was labeled, (ii) the correct label condition in which all AI-generated headlines were labeled (`intervention_label` = &quot;label_Correct&quot;), (iii) the missing label condition in which only half of AI-generated headlines were labeled (`intervention_label` = &quot;label_Missing&quot;), (iv) the noisy label condition in which half of AI-generated headlines were labeled and half of human-generated headlines were mislabeled (`intervention_label` = &quot;label_Noise &quot;), and (v) the false label condition in which false headlines were labeled as false (`intervention_label` = &quot;label_FalseLabel&quot;) </td>\n   <td style=\"text-align:left;\"> The paper's main goal is to test how AI labels affect accuracy judgments. However, this is not the main interest of our study. We will therefor reduce the treatment to the condition in Study 1 where false headlines are labeled as false (`intervention_label` = &quot;label_FalseLabel&quot;). </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n### Notes\n\nIn Study 2, all treatment conditions are only about AI labels. These seem not directly relevant to our study. We will therefore exclude Study 2.\n\n> \"In Study 2 [...] we introduced three new conditions in which participants were provided with definitions explaining what it meant for a headline to be AI-generated. In the Weak Condition, participants were told that AI was used to improve the clarity of the text and adapt its style. In the Medium Condition, participants were told that AI contributed more substantially by writing a first draft of the article, while in the Strong Condition AI chose the topic of the article and wrote the whole article.\"\n\nThe authors do not report an effect on discernment (only an effect is on all accuracy ratings false and true news).\n\n>Regarding our condition of interest--false labels--the authors find that: \"We found that the false labels reduced accuracy and sharing ratings by 0.56 points [-0.70, -0.42]. The false labels had a similar effect on the perceived accuracy of the headlines (b = 0.58 [-0.75, -0.41]) and sharing intentions (b = 0.52 [-0.73, -0.30]).\"\n\n\n## Data Cleaning\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define variables to select\ntarget_variables <- c(\n    \"paper_id\", \"experiment_id\", \"subject_id\", \"news_id\", \"country\", \"year\", \n    \"veracity\", \"condition\", \"intervention_label\", \"intervention_description\", \n    \"intervention_selection\",\n    \"intervention_selection_description\",\n    \"control_selection\",\n    \"accuracy_raw\", \"scale\", \"originally_identified_treatment_effect\", \n    \"concordance\", \"partisan_identity\", \"news_slant\", \"age\", \"age_range\", \"identified_via\", \"id\", \n    \"unique_experiment_id\", \"accuracy\"\n  )\n```\n:::\n\n\n\n\nRead data and inspect key variables.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- read_excel(\"Altay_2023-study_1.xlsx\")\n\n# inspect key variables to get an overview\nd |> \n  select(PROLIFIC_PID, True_False, AI_Human, Condition, Conditions, DV, Ratings, News_number) |> \n  arrange(PROLIFIC_PID)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 31,536 × 8\n   PROLIFIC_PID           True_False AI_Human Condition Conditions DV    Ratings\n   <chr>                  <chr>      <chr>    <chr>     <chr>      <chr>   <dbl>\n 1 54846df3fdf99b0379939… false      AI       FalseLab… FalseLabel Accu…       2\n 2 54846df3fdf99b0379939… true       AI       FalseLab… FalseLabel Accu…       5\n 3 54846df3fdf99b0379939… false      AI       FalseLab… FalseLabel Accu…       2\n 4 54846df3fdf99b0379939… true       AI       FalseLab… FalseLabel Accu…       5\n 5 54846df3fdf99b0379939… false      AI       FalseLab… FalseLabel Accu…       2\n 6 54846df3fdf99b0379939… true       AI       FalseLab… FalseLabel Accu…       5\n 7 54846df3fdf99b0379939… false      AI       FalseLab… FalseLabel Accu…       2\n 8 54846df3fdf99b0379939… true       AI       FalseLab… FalseLabel Accu…       6\n 9 54846df3fdf99b0379939… false      human    FalseLab… FalseLabel Accu…       2\n10 54846df3fdf99b0379939… true       human    FalseLab… FalseLabel Accu…       6\n# ℹ 31,526 more rows\n# ℹ 1 more variable: News_number <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n### Conditions\n\nGet an overview of conditions. There are two candidate variables (`Condition` and `Conditions`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(d$Condition, useNA = \"always\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   Control    Correct FalseLabel    Missing      Noise       <NA> \n      6320       6288       6288       6304       6336          0 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(d$Conditions, useNA = \"always\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n          Control           Correct        FalseLabel           Missing \n             6320              6288              6288              6304 \nNoise_mislabelled  Noise_unlabelled              <NA> \n             1584              4752                 0 \n```\n\n\n:::\n:::\n\n\n\n\nThe `Conditions` variable is slightly more detailed, with two noise conditons. However, since in the paper the authors only report 5 conditions corresponding to the `Condition` variable, we will rely on that one.\n\n### Accuracy\n\nCheck the dependent variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(d$DV, useNA= \"always\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAccuracy  Sharing     <NA> \n   15792    15744        0 \n```\n\n\n:::\n:::\n\n\n\n\nThe data is in long format data, such tat `Ratings` codes the outcome score for both sharing and accuracy. We reduce the data to only accuracy ratings.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# long format data, `Ratings` codes the outcome for both sharing and accuracy, \n# so we have to filter DV == Accuracy. \n# Also, remove some treatment conditions that are irrelevant for our study\nd <- d |> \n  filter(DV == \"Accuracy\")\n```\n:::\n\n\n\n\n### Veracity\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |> \n  mutate(\n    veracity = ifelse(True_False == \"false\", \"false\", \"true\")\n    )\n```\n:::\n\n\n\n\n\n### News id\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd |> \n  group_by(News_number) |> \n  count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 2\n# Groups:   News_number [8]\n  News_number     n\n        <dbl> <int>\n1           1  1974\n2           2  1974\n3           3  1974\n4           4  1974\n5           5  1974\n6           6  1974\n7           7  1974\n8           8  1974\n```\n\n\n:::\n:::\n\n\n\nThere are only 8 different news ids. However, from the paper, we know that there were 8 different news items per veracity condition (i.e. 8 true and 8 false items). We thus build a new news identifier variable combining the two. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |> \n  mutate(news_id = paste0(veracity, \"_\", News_number))\n```\n:::\n\n\n\n\n### Partisan Identity\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |> \n  mutate(partisan_identity = tolower(Political_orientation))\n```\n:::\n\n\n\n\n### Clean data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make final data\naltay_2023 <- d |> \n  mutate(\n    subject_id = PROLIFIC_PID,\n    # make sure that the control conditions has no intervention label\n    intervention_label = ifelse(str_detect(Condition, \"Control\"),\n                                NA,\n                                paste0(\"label_\", Condition)), \n    # keep different labels for control conditions, code treatment as \"treatment\"\n    condition = ifelse(Condition == \"Control\", \"control\", \"treatment\"),\n    accuracy_raw = Ratings,\n    experiment_id = 1,\n    age = Age,\n    scale = 6, \n    country = \"United States\",\n    paper_id = \"altay_2023\") |> \n  # add_intervention_info \n  bind_cols(intervention_info) |> \n  select(any_of(target_variables))\n\n\n# check conditions\n# Altay_2023 |>\n#   group_by(condition) |>\n#   reframe(unique(intervention_label))\n```\n:::\n\n\n\n\n### Write out data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave_data(altay_2023)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}