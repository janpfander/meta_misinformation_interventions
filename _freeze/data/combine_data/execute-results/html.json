{
  "hash": "8823b5e35f1d7f6eff1be2a2c48d2497",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Combine data\"\ntitle-block-banner: true\nexecute:\n  message: false\n  warning: false\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n## A single data frame\n\nAfter having cleaned all individual studies and put the data into a shared format, we combine the studies into a single data frame. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# combine data\n\n# List all matching files recursively\nfiles <- list.files(\n  path = \"papers\", \n  pattern = \"^cleaned.*\\\\.rds$\", \n  full.names = TRUE, \n  recursive = TRUE\n)\n\n# Load each file into a named list\nstudies_data <- lapply(files, function(file) {\n  readRDS(file) |> \n    # remove old labels from stata files \n    haven::zap_labels() |> \n    # ensure all identifier variables are of same variable type\n    mutate(subject_id = as.character(subject_id), \n           scale = as.character(scale))\n})\n\n# Name list elements based on filenames (without extension or path)\nnames(studies_data) <- tools::file_path_sans_ext(basename(files))\n\ndata <- bind_rows(studies_data)\n```\n:::\n\n\n\n\n## Control and intervention group selection\n\nSeveral experiments have multiple control and/or intervention groups. For our meta-analysis, for each experiment, we only pair one control and one treatment group. In a case where we needed to make a selection, we have coded our selection choice in the variables `intervention_selection` and  `control_selection`. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |>\n  # for cases where there was an intervention selection, make sure to only pick the selected intervention\n  filter(is.na(intervention_selection) | intervention_label == intervention_selection | condition == \"control\") |> \n  # same but for the control\n  filter(is.na(control_selection) | control_label == control_selection | condition == \"treatment\")\n\n# check\n# data |> \n#   group_by(paper_id, condition) |> \n#   summarise(sum(!is.na(accuracy_raw)))\n\n# check transformation with dias paper\n# data |> \n#   filter(paper_id == \"dias_2020\") |> \n#   filter(experiment_id == 1) |> \n#   distinct(condition, control_label, control_selection, intervention_label, intervention_selection) \n```\n:::\n\n\n\n\n## Collapse accuracy measures\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  # collapes all raw accuracy scores on different scales into a binary scale\n  mutate(\n    # make a numeric version of scale, for all scales that are not binary\n    scale_numeric = as.numeric(scale),\n    # add helper variable that indicates whether a scale has a midpoint\n    midpoint_scale = ifelse(scale_numeric %% 2 != 0, TRUE, FALSE),\n    accuracy = case_when(\n      # for scales with midpoints, code midpoints as NA\n      midpoint_scale == TRUE & \n        accuracy_raw == (scale_numeric/2)+0.5 ~ NA,\n      # transform continuous scores\n      accuracy_raw <= scale_numeric/2 ~ 0, \n      accuracy_raw > scale_numeric/2 ~ 1, \n      TRUE ~ accuracy_raw)\n    )\n\n# check\n# data |>\n#   distinct(scale, accuracy, accuracy_raw)\n```\n:::\n\n\n\n\n## Make unique paper, experiment, and subject identifiers\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n    mutate(    \n    # unique experiment identifier\n    unique_experiment_id = paste(paper_id, experiment_id, sep = \"_\"), \n    # unique participant identifier\n    unique_subject_id = paste0(paper_id, \"_\", experiment_id, \"_\", subject_id)\n    )\n```\n:::\n\n\n\n\n## Use deviation coding\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |> \n  mutate(    \n    # make numeric helper variables using deviation coding\n    veracity_numeric = ifelse(veracity == \"true\", 0.5, -0.5),\n    condition_numeric = ifelse(condition == \"treatment\",  0.5, -0.5)\n  )\n```\n:::\n\n\n\n\n## Exclude long_term effects\n\nSome studies measured long_term effects. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  filter(long_term == TRUE) |> \n  distinct(paper_id)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 1\n  paper_id  \n  <chr>     \n1 guess_2020\n```\n\n\n:::\n\n```{.r .cell-code}\n# detailed check\n# data |> \n#   filter(paper_id == \"guess_2020\") |> \n#   group_by(long_term) |> \n#   count()\n```\n:::\n\n\n\n\nWe want to exclude these from the main analysis (including them would likely reduce the detected average treatment effect, as effects tend to regress over time). \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |>\n  filter(\n    # remove long term effects\n    long_term == FALSE | is.na(long_term)\n  )\n\n# check\n# table(data$long_term, useNA = \"always\")\n```\n:::\n\n\n\n\n## Save data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# build additional variables\n# Save as CSV\nwrite_csv(data, \"data.csv\")\n\n# Save as RDS\nsaveRDS(data, \"data.rds\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}